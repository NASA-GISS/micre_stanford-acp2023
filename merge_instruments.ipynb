{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d82a81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=========================================================\n",
    "# merge_instruments.py\n",
    "# Author: McKenna W. Stanford\n",
    "# Pulls in various datastreams and merges them into a single\n",
    "# dictinary for a given date. For time and/or height data,\n",
    "# the data is interpolated onto the BASTA time-height grid\n",
    "# of 12 seconds and 25 m. Writes the resulting dictionary\n",
    "# to a pickle file.\n",
    "#========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cdab11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------\n",
    "# Imports\n",
    "#--------------------------------\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import xarray\n",
    "import datetime\n",
    "import calendar\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "from file_struct import file_struct as fs\n",
    "from load_sonde_data import load_sonde_data\n",
    "from give_me_files_and_subfolders import give_me_files_and_subfolders\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.interpolate import NearestNDInterpolator as nn\n",
    "from scipy.interpolate import griddata as griddata\n",
    "from calculate_theta_and_more import calculate_theta_and_more\n",
    "import pandas\n",
    "import metpy.calc as mpcalc\n",
    "from metpy.units import units\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D\n",
    "from scipy.interpolate import interp2d\n",
    "from scipy.interpolate import griddata\n",
    "#import act\n",
    "import metpy\n",
    "import metpy.calc as mpcalc\n",
    "from metpy.cbook import get_test_data\n",
    "from metpy.plots import add_metpy_logo, SkewT\n",
    "from metpy.units import units\n",
    "import time\n",
    "from dask.distributed import Client, progress, LocalCluster\n",
    "import csv\n",
    "#import seaborn as sns\n",
    "#--------------------------------------------\n",
    "#--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c41b259f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------\n",
    "# Functions\n",
    "#--------------------------------------------\n",
    "def toTimestamp(d):\n",
    "    return calendar.timegm(d.timetuple())\n",
    "\n",
    "def toDatetime(d):\n",
    "    return datetime.datetime.utcfromtimestamp(d)\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx],idx   \n",
    "\n",
    "# function to make serial date numbers which are the number of days that have passed\n",
    "# since epoch beginning given as days.fraction_of_day\n",
    "def datenum(d):\n",
    "        return 366 + d.toordinal() + (d - datetime.datetime.fromordinal(d.toordinal())).total_seconds()/(24*60*60)\n",
    "#--------------------------------------------\n",
    "#--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e927be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================================\n",
    "# Grab BASTA files\n",
    "#==================================================\n",
    "basta_path = '/mnt/raid/mwstanfo/micre_data/micre_basta/BASTA_25m/'\n",
    "basta_files = glob.glob(basta_path+'*.nc')\n",
    "basta_files = sorted(basta_files)\n",
    "basta_files = np.array(basta_files)\n",
    "\n",
    "basta_dates_dt = []\n",
    "for ii in range(len(basta_files)):\n",
    "    fname = basta_files[ii]\n",
    "    tmp_str = fname.split('_')\n",
    "    tmp_str = tmp_str[-1]\n",
    "    tmp_str = tmp_str.split('.')\n",
    "    tmp_str = tmp_str[0]\n",
    "    tmp_year = int(tmp_str[0:4])\n",
    "    tmp_month = int(tmp_str[4:6])\n",
    "    tmp_day = int(tmp_str[6:8])\n",
    "    basta_dates_dt.append(datetime.datetime(tmp_year,tmp_month,tmp_day,0,0,0))\n",
    "basta_dates_dt = np.array(basta_dates_dt)\n",
    "dates = basta_dates_dt.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0f9857e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================================\n",
    "# Grab ARM Ceilometer files\n",
    "#==================================================\n",
    "arm_ceil_path = '/mnt/raid/mwstanfo/micre_data/micre_ceil/'\n",
    "arm_ceil_files = glob.glob(arm_ceil_path+'*.nc')\n",
    "arm_ceil_files = sorted(arm_ceil_files)\n",
    "arm_ceil_files = np.array(arm_ceil_files)\n",
    "\n",
    "arm_ceil_dates_dt = []\n",
    "for ii in range(len(arm_ceil_files)):\n",
    "    fname = arm_ceil_files[ii]\n",
    "    tmp_str = fname.split('/')\n",
    "    tmp_str = tmp_str[-1]\n",
    "    tmp_str = tmp_str.split('.')\n",
    "    tmp_str = tmp_str[2]\n",
    "    tmp_year = int(tmp_str[0:4])\n",
    "    tmp_month = int(tmp_str[4:6])\n",
    "    tmp_day = int(tmp_str[6:8])\n",
    "    arm_ceil_dates_dt.append(datetime.datetime(tmp_year,tmp_month,tmp_day,0,0,0))\n",
    "arm_ceil_dates_dt = np.array(arm_ceil_dates_dt)\n",
    "\n",
    "# Limit ceilometer files to encompass only BASTA dates\n",
    "tmpid = np.where((arm_ceil_dates_dt >= basta_dates_dt[0]) & (arm_ceil_dates_dt <= basta_dates_dt[-1]))[0]\n",
    "arm_ceil_files = arm_ceil_files[tmpid]\n",
    "arm_ceil_dates_dt = arm_ceil_dates_dt[tmpid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e637ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================================\n",
    "# Grab University of Canterbury Ceilometer files\n",
    "#==================================================\n",
    "aad_ceil_path = '/mnt/raid/mwstanfo/micre_data/aad_ceil/merged/'\n",
    "aad_ceil_files = glob.glob(aad_ceil_path+'*.nc')\n",
    "aad_ceil_files = sorted(aad_ceil_files)\n",
    "aad_ceil_files = np.array(aad_ceil_files)\n",
    "\n",
    "\n",
    "aad_ceil_dates_dt = []\n",
    "for ii in range(len(aad_ceil_files)):\n",
    "    fname = aad_ceil_files[ii]\n",
    "    tmp_str = fname.split('/')\n",
    "    tmp_str = tmp_str[-1]\n",
    "    tmp_str = tmp_str.split('.')\n",
    "    tmp_str = tmp_str[0]\n",
    "    tmp_str = tmp_str.split('_')\n",
    "    tmp_year = int(tmp_str[3])\n",
    "    tmp_month = int(tmp_str[4])\n",
    "    tmp_day = int(tmp_str[5])\n",
    "    aad_ceil_dates_dt.append(datetime.datetime(tmp_year,tmp_month,tmp_day))\n",
    "    \n",
    "aad_ceil_dates_dt = np.array(aad_ceil_dates_dt)\n",
    "# Limit ceilometer files to encompass only BASTA dates\n",
    "tmpid = np.where((aad_ceil_dates_dt >= basta_dates_dt[0]) & (aad_ceil_dates_dt <= basta_dates_dt[-1]))[0]\n",
    "aad_ceil_dates_dt = aad_ceil_dates_dt[tmpid] \n",
    "aad_ceil_files = aad_ceil_files[tmpid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02af9ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================================\n",
    "# Grab surface meteorology files\n",
    "#==================================================\n",
    "sfc_path = '/mnt/raid/mwstanfo/micre_data/micre_sfc/'\n",
    "sfc_files = glob.glob(sfc_path+'*.nc')\n",
    "sfc_files = sorted(sfc_files)\n",
    "sfc_files = np.array(sfc_files)\n",
    "\n",
    "sfc_dates_dt = []\n",
    "for ii in range(len(sfc_files)):\n",
    "    fname = sfc_files[ii]\n",
    "    tmp_str = fname.split('/')\n",
    "    tmp_str = tmp_str[-1]\n",
    "    tmp_str = tmp_str.split('.')\n",
    "    tmp_str = tmp_str[2]\n",
    "    tmp_year = int(tmp_str[0:4])\n",
    "    tmp_month = int(tmp_str[4:6])\n",
    "    tmp_day = int(tmp_str[6:8])\n",
    "    sfc_dates_dt.append(datetime.datetime(tmp_year,tmp_month,tmp_day,0,0,0))\n",
    "sfc_dates_dt = np.array(sfc_dates_dt)\n",
    "\n",
    "# Limit sfc met files to encompass only BASTA dates\n",
    "tmpid = np.where((sfc_dates_dt >= basta_dates_dt[0]) & (sfc_dates_dt <= basta_dates_dt[-1]))[0]\n",
    "sfc_dates_dt = sfc_dates_dt[tmpid] \n",
    "sfc_files = sfc_files[tmpid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db4f4abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================================\n",
    "# Grab satellite files\n",
    "#==================================================\n",
    "sat_path = '/mnt/raid/mwstanfo/micre_data/visst_gridded/'\n",
    "sat_files = glob.glob(sat_path+'*.nc')\n",
    "sat_files = sorted(sat_files)\n",
    "sat_files = np.array(sat_files)\n",
    "\n",
    "sat_dates_dt = []\n",
    "for ii in range(len(sat_files)):\n",
    "    fname = sat_files[ii]\n",
    "    tmp_str = fname.split('/')\n",
    "    tmp_str = tmp_str[-1]\n",
    "    tmp_str = tmp_str.split('.')\n",
    "    tmp_str = tmp_str[0]\n",
    "    tmp_str = tmp_str.split('_')\n",
    "    tmp_str = tmp_str[2:]\n",
    "    tmp_year = int(tmp_str[0])\n",
    "    tmp_month = int(tmp_str[1])\n",
    "    tmp_day = int(tmp_str[2])\n",
    "    sat_dates_dt.append(datetime.datetime(tmp_year,tmp_month,tmp_day,0,0,0))\n",
    "sat_dates_dt = np.array(sat_dates_dt)\n",
    "\n",
    "# sort files according to dates\n",
    "sort_id = np.argsort(sat_dates_dt)\n",
    "sat_dates_dt = sat_dates_dt[sort_id]\n",
    "sat_files = sat_files[sort_id]\n",
    "\n",
    "# Limit sat files to encompass only BASTA dates\n",
    "tmpid = np.where((sat_dates_dt >= basta_dates_dt[0]) & (sat_dates_dt <= basta_dates_dt[-1]))[0]\n",
    "sat_dates_dt = sat_dates_dt[tmpid] \n",
    "sat_files = sat_files[tmpid]\n",
    "#--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ce6715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================================\n",
    "# Grab optics files\n",
    "#==================================================\n",
    "path = '/mnt/raid/mwstanfo/micre_data/micre_optics/'\n",
    "optics_files = glob.glob(path+'*.cdf')\n",
    "optics_files = sorted(optics_files)\n",
    "optics_files = np.array(optics_files)\n",
    "nf = len(optics_files)\n",
    "#print(optics_files)\n",
    "\n",
    "optics_dates_dt = []\n",
    "for ff in range(nf):\n",
    "    optics_file = optics_files[ff]\n",
    "    optics_file = str.split(optics_file,'/')[-1]\n",
    "    optics_file = str.split(optics_file,'.')[-3]\n",
    "    year = int(optics_file[0:4])\n",
    "    month = int(optics_file[4:6])\n",
    "    day = int(optics_file[6:8])\n",
    "    optics_date_dt = datetime.datetime(year,month,day)\n",
    "    optics_dates_dt.append(optics_date_dt)\n",
    "optics_dates_dt = np.array(optics_dates_dt)\n",
    "# limit to only basta times\n",
    "tmpid = np.where((optics_dates_dt >= basta_dates_dt[0]) & (optics_dates_dt <= basta_dates_dt[-1]))[0]\n",
    "optics_files = optics_files[tmpid]\n",
    "optics_dates_dt = optics_dates_dt[tmpid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "581c7608",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "#if True:\n",
    "    sns.set_theme()\n",
    "    #sns.set_style('dark')\n",
    "    sns.set_style('ticks')\n",
    "    sns.set(rc={'axes.facecolor':'lavender','axes.edgecolor': 'black','grid.color':'white'})\n",
    "    sns.set_context('talk') \n",
    "\n",
    "    # Look at optics files\n",
    "    ii=0\n",
    "    for file in optics_files[10:]:\n",
    "        print(file)\n",
    "        ncfile = xarray.open_dataset(file,decode_times=False)\n",
    "        base_time = ncfile['base_time'].values\n",
    "        time_offset = ncfile['time_offset'].values\n",
    "        qc_time = ncfile['qc_time'].values\n",
    "        tau_inst = ncfile['optical_depth_instantaneous'].values\n",
    "        qc_tau_inst = ncfile['qc_optical_depth_instantaneous'].values\n",
    "        reff_inst = ncfile['effective_radius_instantaneous'].values\n",
    "        qc_reff_inst = ncfile['qc_effective_radius_instantaneous'].values\n",
    "        tau_avg = ncfile['optical_depth_instantaneous'].values\n",
    "        qc_tau_avg = ncfile['qc_optical_depth_average'].values\n",
    "        reff_avg = ncfile['effective_radius_average'].values\n",
    "        qc_reff_avg = ncfile['qc_effective_radius_average'].values\n",
    "        trans1 = ncfile['total_transmittance_filter1'].values\n",
    "        trans2 = ncfile['total_transmittance_filter2'].values\n",
    "        trans3 = ncfile['total_transmittance_filter3'].values\n",
    "        trans4 = ncfile['total_transmittance_filter4'].values\n",
    "        trans5 = ncfile['total_transmittance_filter5'].values\n",
    "        lwp = ncfile['lwp'].values\n",
    "        qc_lwp = ncfile['qc_lwp'].values\n",
    "        pwv = ncfile['pwv'].values\n",
    "        qc_pwv = ncfile['qc_pwv'].values\n",
    "        cf = ncfile['cloudfraction'].values\n",
    "        qc_cf = ncfile['qc_cloudfraction'].values\n",
    "        ncfile.close()\n",
    "        time_ts = base_time + time_offset\n",
    "        time_dt = np.array([toDatetime(time_ts[dd]) for dd in range(len(time_ts))])\n",
    "\n",
    "              \n",
    "\n",
    "        fig = plt.figure(figsize=(20,14))\n",
    "        ax_tau = fig.add_subplot(321)\n",
    "        ax_reff = fig.add_subplot(322)\n",
    "        ax_lwp = fig.add_subplot(323)\n",
    "        ax_cf = fig.add_subplot(324)\n",
    "        ax_trans = fig.add_subplot(325)\n",
    "        Fontsize=16\n",
    "        dfmt = mdates.DateFormatter('%H:%M')\n",
    "\n",
    "        ax_list = [ax_tau,ax_reff,ax_lwp,ax_cf,ax_trans]\n",
    "        for ax in ax_list:\n",
    "            ax.grid(True)\n",
    "            ax.tick_params(labelsize=Fontsize)\n",
    "            ax.xaxis.set_major_formatter(dfmt)\n",
    "            ax.set_xlabel('UTC Time [HH:MM]',fontsize=Fontsize)\n",
    "            ax.set_axisbelow(True)\n",
    "\n",
    "        ax_tau.set_title('Optical Depth ($\\\\tau$)',fontsize=Fontsize*1.5,fontweight='bold')\n",
    "        ax_tau.set_ylabel('$\\\\tau$',fontsize=Fontsize)\n",
    "        ax_reff.set_title('Effective Radius ($R_{eff}$)',fontsize=Fontsize*1.5,fontweight='bold')\n",
    "        ax_reff.set_ylabel('$R_{eff}$ [$\\\\mu$m]',fontsize=Fontsize)\n",
    "        ax_lwp.set_title('Liquid Water Path (LWP)',fontsize=Fontsize*1.5,fontweight='bold')\n",
    "        ax_lwp.set_ylabel('LWP [g m$^{-2}$]',fontsize=Fontsize)\n",
    "        ax_cf.set_title('Cloud Fraction',fontsize=Fontsize*1.5,fontweight='bold')\n",
    "        ax_cf.set_ylabel('Cloud Fraction',fontsize=Fontsize)\n",
    "        ax_tau.set_yscale('log')\n",
    "        ax_lwp.set_yscale('log')\n",
    "        ax_trans.set_title('Total transmittance of Narrowband\\nHemispheric Irradiance',fontsize=Fontsize,fontweight='bold')\n",
    "        ax_trans.set_ylabel('Transmittance',fontsize=Fontsize)\n",
    "        ax_cf.set_ylabel('Cloud Fraction',fontsize=Fontsize)\n",
    "        \n",
    "        # Plot\n",
    "        ax_tau.plot(time_dt,tau_inst,label='$\\\\tau_{inst}$',c='black',lw=2)\n",
    "        ax_tau.plot(time_dt,tau_avg,label='$\\\\tau_{avg}$',c='red',lw=2,ls='dashed')\n",
    "        ax_tau.legend(loc='upper left',fontsize=Fontsize)\n",
    "        ax_reff.plot(time_dt,reff_inst,label='$R_{eff,inst}$',c='black',lw=2)\n",
    "        ax_reff.plot(time_dt,reff_avg,label='$R_{eff,avg}$',c='red',lw=2,ls='dashed')\n",
    "        ax_reff.legend(loc='upper left',fontsize=Fontsize)\n",
    "        ax_lwp.plot(time_dt,lwp,c='black',lw=2)\n",
    "        ax_cf.plot(time_dt,cf,c='black',lw=2)\n",
    "        ax_trans.plot(time_dt,trans1,c='black',lw=1,label='Filter 1')\n",
    "        ax_trans.plot(time_dt,trans1,c='red',lw=1,label='Filter 2')\n",
    "        ax_trans.plot(time_dt,trans3,c='darkorange',lw=1,label='Filter 3')\n",
    "        ax_trans.plot(time_dt,trans4,c='blue',lw=1,label='Filter 4')\n",
    "        ax_trans.plot(time_dt,trans5,c='deepskyblue',lw=1,label='Filter 5')\n",
    "        ax_trans.legend(loc='upper center',fontsize=Fontsize,ncol=2)\n",
    "\n",
    "        dumdate = datetime.datetime(time_dt[0].year,time_dt[0].month,time_dt[0].day)\n",
    "        dumdate = dumdate.strftime('%Y/%m/%d')\n",
    "        plt.suptitle(dumdate,fontsize=Fontsize*2.,fontweight='bold')\n",
    "        plt.subplots_adjust(hspace=0.4)\n",
    "\n",
    "        plt.show()\n",
    "        print(aaaa)\n",
    "\n",
    "        dumdate = datetime.datetime(time_dt[0].year,time_dt[0].month,time_dt[0].day)\n",
    "        dumdate = dumdate.strftime('%Y%m%d')\n",
    "        fig_path = '/home/mwstanfo/figures/micre_v2/optics/'\n",
    "        outfile = 'optics_{}.png'.format(dumdate)\n",
    "        plt.savefig(fig_path+outfile,dpi=200,bbox_inches='tight')       \n",
    "        plt.close()    \n",
    "        ii+=1\n",
    "\n",
    "        #print(aaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f277ad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================================\n",
    "# Grab sounding files\n",
    "#==================================================\n",
    "path = '/mnt/raid/mwstanfo/micre_data/micre_soundings/'\n",
    "sonde_files = glob.glob(path+'*.nc')\n",
    "sonde_files = sorted(sonde_files)\n",
    "sonde_files = np.array(sonde_files)\n",
    "nf = len(sonde_files)\n",
    "\n",
    "sonde_dates_dt = []\n",
    "sonde_times_dt = []\n",
    "for ff in range(nf):\n",
    "    sonde_file = sonde_files[ff]\n",
    "    sonde_file = str.split(sonde_file,'/')[-1]\n",
    "    sonde_file = str.split(sonde_file,'.')[0]\n",
    "    sonde_file_str1 = str.split(sonde_file,'_')[0]\n",
    "    sonde_file_str2 = str.split(sonde_file,'_')[1]\n",
    "    year = int(sonde_file_str1[0:4])\n",
    "    month = int(sonde_file_str1[4:6])\n",
    "    day = int(sonde_file_str1[6:8])\n",
    "    hour = int(sonde_file_str2[0:2])\n",
    "    minute = int(sonde_file_str2[2:4])\n",
    "    sonde_time_dt = datetime.datetime(year,month,day,hour,minute)\n",
    "    sonde_date_dt = datetime.datetime(year,month,day)\n",
    "    sonde_dates_dt.append(sonde_date_dt)\n",
    "    sonde_times_dt.append(sonde_time_dt)\n",
    "sonde_dates_dt = np.array(sonde_dates_dt)\n",
    "sonde_times_dt = np.array(sonde_times_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e13f0dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#==================================================\n",
    "# Grab cluster files\n",
    "#==================================================\n",
    "cluster_file ='/mnt/raid/mwstanfo/micre/cluster_information_all.xlsx'\n",
    "\n",
    "clusters = pd.read_excel(cluster_file)\n",
    "clusters = np.array(clusters)\n",
    "cluster_number = clusters[:,0]\n",
    "cluster_dates = clusters[:,1]\n",
    "cluster_ids = clusters[:,2]\n",
    "\n",
    "cluster_dates_dt = []\n",
    "cluster_times_dt = []\n",
    "for cluster_date in cluster_dates:\n",
    "    tmpstr1,tmpstr2 = str.split(cluster_date,'_')\n",
    "    tmpyear = int(tmpstr1[0:4])\n",
    "    tmpmonth = int(tmpstr1[4:6])\n",
    "    tmpday = int(tmpstr1[6:8])\n",
    "    tmphour = int(tmpstr2[0:2])\n",
    "    tmpminute = int(tmpstr2[2:4])\n",
    "    cluster_times_dt.append(datetime.datetime(tmpyear,tmpmonth,tmpday,tmphour,tmpminute))\n",
    "    cluster_dates_dt.append(datetime.datetime(tmpyear,tmpmonth,tmpday))\n",
    "cluster_dates_dt = np.array(cluster_dates_dt)\n",
    "cluster_times_dt = np.array(cluster_times_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb0087ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================================\n",
    "# Grab disdrometer (PIRAT) files\n",
    "#==================================================\n",
    "dis_path = '/mnt/raid/mwstanfo/micre_data/micre_disdrometer/PIRAT_rates_csv/'\n",
    "dis_files = glob.glob(dis_path+'*.csv')\n",
    "dis_files = sorted(dis_files)\n",
    "dis_files = np.array(dis_files)\n",
    "dis_dates_dt = []\n",
    "\n",
    "for ii in range(len(dis_files)):\n",
    "    tmp_str = dis_files[ii].split('/')\n",
    "    tmp_str = tmp_str[-1]\n",
    "    tmp_str = tmp_str.split('_')\n",
    "    tmp_str = tmp_str[1]\n",
    "    tmp_str = tmp_str.split('.')\n",
    "    tmp_str = tmp_str[0]\n",
    "    tmp_year = int(tmp_str[0:4])\n",
    "    tmp_month = int(tmp_str[4:6])\n",
    "    tmp_day = int(tmp_str[6:8])\n",
    "    dis_dates_dt.append(datetime.datetime(tmp_year,tmp_month,tmp_day))\n",
    "    #dis_data = pd.read_csv(dis_files[ii],delimiter=',',header=0)\n",
    "    #dis_data = np.array(dis_data)\n",
    "    #dis_time = dis_data[:,0] # time in fraction of UTC hour\n",
    "    #dis_DQ = dis_data[:,1] # 0: good, != 0: bad\n",
    "    #dis_R = dis_data[:,2] # precipitation rate in mm/hr\n",
    "dis_dates_dt = np.array(dis_dates_dt)\n",
    "\n",
    "# Limit disdrometer files to encompass only BASTA dates\n",
    "tmpid = np.where((dis_dates_dt >= basta_dates_dt[0]) & (dis_dates_dt <= basta_dates_dt[-1]))[0]\n",
    "dis_dates_dt = dis_dates_dt[tmpid]\n",
    "dis_files = dis_files[tmpid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57be18cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = '/mnt/raid/mwstanfo/micre/merged_instrument_files/'\n",
    "#files = glob.glob(path+'*.p')\n",
    "#files = sorted(files)\n",
    "#infile = files[0]\n",
    "#merged_dict = pickle.load(open(infile,\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "154aea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dis(date,dis_dates_dt,dis_files,avg_bool,basta_time_ts):\n",
    "    tmpid = np.where(dis_dates_dt == date)\n",
    "    if np.size(tmpid) == 0.:\n",
    "        dis_present_flag = False\n",
    "        dis_dict = None\n",
    "        return dis_present_flag,dis_dict\n",
    "    elif np.size(tmpid) > 0.:\n",
    "        dis_present_flag = True\n",
    "        tmpid = tmpid[0][0]\n",
    "        current_dis_file = dis_files[tmpid]\n",
    "        current_dis_date = dis_dates_dt[tmpid]\n",
    "\n",
    "        dis_data = pd.read_csv(current_dis_file,delimiter=',',header=0)\n",
    "        dis_data = np.array(dis_data)\n",
    "        dis_time = dis_data[:,0] # time in fraction of UTC hour\n",
    "        dis_dq = dis_data[:,1] # 0: good, != 0: bad\n",
    "        dis_precip_rate = dis_data[:,2] # precipitation rate in mm/hr\n",
    "\n",
    "        # convert dis_time from fraction of UTC hour to datetime object and timestamp\n",
    "        dis_date = current_dis_date\n",
    "        dis_year = dis_date.year\n",
    "        dis_month = dis_date.month\n",
    "        dis_day = dis_date.day\n",
    "        dis_hour = np.array([np.floor(dis_time[dd]) for dd in range(len(dis_time))])\n",
    "        fraction_of_hour = np.array([(dis_time[dd]-dis_hour[dd]) for dd in range(len(dis_time))])\n",
    "        dis_minute = fraction_of_hour*60.\n",
    "\n",
    "        dis_time_dt = np.array([datetime.datetime(dis_year,\\\n",
    "                                                  dis_month,\\\n",
    "                                                  dis_day,\\\n",
    "                                                  int(dis_hour[dd]),\\\n",
    "                                                  int(dis_minute[dd])) for dd in range(len(dis_time))])\n",
    "        dis_time_ts = np.array([toTimestamp(dis_time_dt[dd]) for dd in range(len(dis_time))])\n",
    "\n",
    "        # NaN out bad values\n",
    "        dis_precip_rate[dis_dq > 0.] = np.nan\n",
    "        \n",
    "        dis_dict = {'precip_rate':dis_precip_rate,'time_dt':dis_time_dt,'time_ts':dis_time_ts} \n",
    "        return dis_present_flag, dis_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63b315cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sfc_met(date,sfc_dates_dt,sfc_files,avg_bool,basta_time_ts):\n",
    "\n",
    "    tmpid = np.where(sfc_dates_dt == date)\n",
    "    if np.size(tmpid) == 0.:\n",
    "        sfc_met_present_flag = False\n",
    "        sfc_met_out_dict = None\n",
    "        return sfc_met_present_flag, sfc_met_out_dict\n",
    "    elif np.size(tmpid) > 0.:        \n",
    "        sfc_met_present_flag = True\n",
    "        tmpid = tmpid[0][0]\n",
    "        current_sfc_file = sfc_files[tmpid]\n",
    "        \n",
    "        ncfile = xarray.open_dataset(current_sfc_file,decode_times=False)\n",
    "        sfc_dims = ncfile.dims\n",
    "        sfc_base_time = np.array(ncfile['base_time'].copy())\n",
    "        sfc_num_times = sfc_dims['time']\n",
    "        sfc_time_offset = np.array(ncfile['time_offset'].copy())\n",
    "        sfc_temperature = np.array(ncfile['temperature'].copy())\n",
    "        sfc_pressure = np.array(ncfile['pressure'].copy())\n",
    "        sfc_rh = np.array(ncfile['relative_humidity'].copy())\n",
    "        sfc_wind_speed = np.array(ncfile['wind_speed'].copy())\n",
    "        sfc_wind_dir = np.array(ncfile['wind_direction'].copy())\n",
    "        sfc_precip = np.array(ncfile['cumulative_precipitation'].copy())\n",
    "        ncfile.close()\n",
    "\n",
    "        sfc_time_ts = [int(sfc_base_time + sfc_time_offset[dd]) for dd in range(sfc_num_times)]\n",
    "        sfc_time_dt = [toDatetime(sfc_time_ts[dd]) for dd in range(sfc_num_times)]\n",
    "\n",
    "        # NaN out missing values\n",
    "        # original missing value is -9999.\n",
    "        sfc_temperature[sfc_temperature < -950.] = np.nan\n",
    "        sfc_pressure[sfc_pressure < -950.] = np.nan\n",
    "        sfc_rh[sfc_rh < -950.] = np.nan\n",
    "        sfc_wind_speed[sfc_wind_speed < -950.] = np.nan\n",
    "        sfc_wind_dir[sfc_wind_dir < -950.] = np.nan\n",
    "        sfc_precip[sfc_precip < -950.] = np.nan\n",
    "        \n",
    "        # interpolate sfc variables to basta time grid\n",
    "        sfc_temperature_interp = np.interp(basta_time_ts,sfc_time_ts,sfc_temperature)\n",
    "        sfc_rh_interp = np.interp(basta_time_ts,sfc_time_ts,sfc_rh)\n",
    "        sfc_wind_speed_interp = np.interp(basta_time_ts,sfc_time_ts,sfc_wind_speed)\n",
    "        sfc_wind_dir_interp = np.interp(basta_time_ts,sfc_time_ts,sfc_wind_dir,period=360)\n",
    "        sfc_pressure_interp = np.interp(basta_time_ts,sfc_time_ts,sfc_pressure)\n",
    "\n",
    "\n",
    "        sfc_met_out_dict = {'native_temperature':sfc_temperature,\\\n",
    "                    'native_rh':sfc_rh,\\\n",
    "                    'native_pressure':sfc_pressure,\\\n",
    "                    'native_wind_speed':sfc_wind_speed,\\\n",
    "                    'native_wind_dir':sfc_wind_dir,\\\n",
    "                    'native_precip':sfc_precip,\\\n",
    "                    'native_time_dt':sfc_time_dt,\\\n",
    "                    'native_time_ts':sfc_time_ts,\\\n",
    "                    'temperature':sfc_temperature_interp,\\\n",
    "                    'rh':sfc_rh_interp,\\\n",
    "                    'wind_speed':sfc_wind_speed_interp,\\\n",
    "                    'wind_dir':sfc_wind_dir_interp,\\\n",
    "                    'pressure':sfc_pressure_interp,\\\n",
    "                   }\n",
    "\n",
    "        return sfc_met_present_flag,sfc_met_out_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "923c44fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sat(date,sat_dates_dt,sat_files):\n",
    "\n",
    "    tmpid = np.where(sat_dates_dt == date)\n",
    "    if np.size(tmpid) == 0.:\n",
    "        sat_present_flag = False\n",
    "        sat_out_dict = None\n",
    "        return sat_present_flag,sat_out_dict\n",
    "    elif np.size(tmpid) > 0.:\n",
    "        sat_present_flag = True\n",
    "        tmpid = tmpid[0][0]\n",
    "        current_sat_file = sat_files[tmpid]\n",
    "\n",
    "        ncfile = xarray.open_dataset(current_sat_file,decode_times=False)\n",
    "        sat_time_epoch = np.array(ncfile['time_epoch'].copy())\n",
    "        sat_lat = np.array(ncfile['lat'].copy())\n",
    "        sat_lon = np.array(ncfile['lon'].copy())\n",
    "        sat_visible_reflectance = np.array(ncfile['visible_reflectance'].copy())\n",
    "        sat_ir_brightness_temperature = np.array(ncfile['ir_brightness_temperature'].copy())\n",
    "        sat_effective_temperature = np.array(ncfile['effective_temperature'].copy())\n",
    "        sat_lwp = np.array(ncfile['lwp'].copy())\n",
    "        sat_iwp = np.array(ncfile['iwp'].copy())\n",
    "        sat_ice_re = np.array(ncfile['ice_re'].copy())\n",
    "        sat_ice_de = np.array(ncfile['ice_de'].copy())\n",
    "        sat_liq_re = np.array(ncfile['liq_re'].copy())\n",
    "        sat_optical_depth = np.array(ncfile['optical_depth'].copy())\n",
    "        ncfile.close()\n",
    "        sat_time_ts = sat_time_epoch.copy()\n",
    "        sat_time_dt = np.array([toDatetime(sat_time_ts[dd]) for dd in range(len(sat_time_ts))])\n",
    "        \n",
    "\n",
    "        sat_out_dict = {'time_ts':sat_time_ts,\\\n",
    "                        'time_dt':sat_time_dt,\\\n",
    "                        'lon':sat_lon,\\\n",
    "                        'lat':sat_lat,\\\n",
    "                        'visible_reflectance':sat_visible_reflectance,\\\n",
    "                        'ir_brightness_temperature':sat_ir_brightness_temperature,\\\n",
    "                        'ir_effective_temperature':sat_effective_temperature,\\\n",
    "                        'lwp':sat_lwp,\\\n",
    "                        'iwp':sat_iwp,\\\n",
    "                        'ice_re':sat_ice_re,\\\n",
    "                        'ice_de':sat_ice_de,\\\n",
    "                        'liq_re':sat_liq_re,\\\n",
    "                        'optical_depth':sat_optical_depth,\\\n",
    "                       }\n",
    "        \n",
    "\n",
    "        return sat_present_flag, sat_out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b7494f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#target_date = datetime.datetime(2016,5,23)\n",
    "#dumid = np.where(basta_dates_dt == target_date)\n",
    "#in_date = basta_dates_dt[dumid[0]]\n",
    "#interp_sonde_present_flag, sonde_out_dict = interp_sondes(in_date,sonde_dates_dt,sonde_times_dt,sonde_files,merged_dict['basta']['time_dt'],merged_dict['basta']['height'])\n",
    "#print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33baf601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_native_sondes(date,sonde_dates_dt,sonde_times_dt,sonde_files,cluster_ids,cluster_times_dt):\n",
    "    sonde_id = np.where(sonde_dates_dt == date)[0]\n",
    "\n",
    "    # Pull out 3 sounding times (if available) to be included in the output file.\n",
    "    num_soundings = len(sonde_times_dt)\n",
    "    date = date[0]\n",
    "    target_time_1 = datetime.datetime(date.year,date.month,date.day,0)\n",
    "    target_time_2 = datetime.datetime(date.year,date.month,date.day,12)\n",
    "    tmp_time_delta = datetime.timedelta(days=1)\n",
    "    target_time_3 = datetime.datetime(date.year,date.month,date.day,0) + tmp_time_delta\n",
    "    sonde_times_dt = np.array(sonde_times_dt)\n",
    "\n",
    "    \n",
    "    \n",
    "    tmpid = np.where((sonde_times_dt > (target_time_1 - datetime.timedelta(hours=2))) & (sonde_times_dt < (target_time_1 + datetime.timedelta(hours=2))))\n",
    "    if np.size(tmpid) > 0:\n",
    "        sonde_1_id = tmpid[0][0]\n",
    "        sonde_1_flag = True\n",
    "    else:\n",
    "        sonde_1_flag = False\n",
    "        sonde_1_id = -999.\n",
    "    tmpid = np.where((sonde_times_dt > (target_time_2 - datetime.timedelta(hours=2))) & (sonde_times_dt < (target_time_2 + datetime.timedelta(hours=2))))\n",
    "    if np.size(tmpid) > 0:\n",
    "        sonde_2_id = tmpid[0][0]\n",
    "        sonde_2_flag = True\n",
    "    else:\n",
    "        sonde_2_flag = False\n",
    "        sonde_2_id = -999.\n",
    "    tmpid = np.where((sonde_times_dt > (target_time_3 - datetime.timedelta(hours=2))) & (sonde_times_dt < (target_time_3 + datetime.timedelta(hours=2))))\n",
    "    if np.size(tmpid) > 0:\n",
    "        sonde_3_id = tmpid[0][0]\n",
    "        sonde_3_flag = True\n",
    "    else:\n",
    "        sonde_3_flag = False \n",
    "        sonde_3_id = -999.\n",
    "    \n",
    "    sonde_flags = [sonde_1_flag,sonde_2_flag,sonde_3_flag]\n",
    "    sonde_ids = [sonde_1_id,sonde_2_id,sonde_3_id]    \n",
    "\n",
    "\n",
    "\n",
    "    native_sonde_dict = {}\n",
    "    for jj in range(len(sonde_flags)):\n",
    "        if not sonde_flags[jj]:\n",
    "            native_sonde_dict[str(int(jj+1))] = None\n",
    "            continue\n",
    "        elif sonde_flags[jj]:\n",
    "            current_sonde_id = sonde_ids[jj]\n",
    "            current_sonde_file = sonde_files[current_sonde_id]\n",
    "            current_sonde_time = sonde_times_dt[current_sonde_id]\n",
    "            dumid = np.where(cluster_times_dt == current_sonde_time)\n",
    "            if np.size(dumid) > 0.:\n",
    "                current_cluster_id = cluster_ids[dumid[0][0]]\n",
    "            else:\n",
    "                current_cluster_id = None\n",
    "            # Calculate everything\n",
    "            current_sonde_file = current_sonde_file.split('/')[-1]\n",
    "            path = '/mnt/raid/mwstanfo/micre_data/micre_soundings/'\n",
    "            file_size = os.stat(path+current_sonde_file).st_size/1.e3\n",
    "            fstruct = fs(current_sonde_file,path,file_size)\n",
    "            Sondetmp = load_sonde_data(fstruct)\n",
    "            \n",
    "            #['site_lat', 'site_lon', 'sfc_pressure', 'sfc_temp', 'sfc_humidity',\\\n",
    "            # 'sfc_wind_speed', 'sfc_wind_direction', 'dewpoint_temp', 'drybulb_temp', \\\n",
    "            # 'RH', 'pressure', 'wind_direction', 'u_wind', 'v_wind', 'wind_speed', \\\n",
    "            # 'ascent_rate', 'lat', 'lon', 'alt', 'time', 'units', 'long_name']            \n",
    "\n",
    "            max_alt = np.max(Sondetmp['alt'])\n",
    "            if max_alt < 10.:\n",
    "                print('Sonde failed to reach 10 km. Therefore omitting this sounding.')\n",
    "                native_sonde_dict[str(int(jj+1))] = None\n",
    "                sonde_flags[jj] = False\n",
    "                continue\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            # Calculate EIS, LTS, and LCL\n",
    "            Moretmp = calculate_theta_and_more(Sondetmp['drybulb_temp'],Sondetmp['pressure'],\\\n",
    "                                           RH=Sondetmp['RH'],use_T_K=True,\\\n",
    "                                          sat_pres_formula='Emmanuel')\n",
    "            \n",
    "            nearest_val_700hpa,nearest_id_700hpa = find_nearest(Sondetmp['pressure'],700)\n",
    "            theta_700hpa = Moretmp['Theta'][nearest_id_700hpa] # in K\n",
    "            temp_700hpa = Sondetmp['drybulb_temp'][nearest_id_700hpa] # in K\n",
    "            z_700hpa = Sondetmp['alt'][nearest_id_700hpa]*1.e3 # in meters\n",
    "            tmp_sfc_temp = Sondetmp['drybulb_temp'][0] # in K\n",
    "            tmp_sfc_pres = Sondetmp['pressure'][0] # in hPa\n",
    "            tmp_sfc_rh = Sondetmp['RH'][0] # in %\n",
    "\n",
    "            \n",
    "\n",
    "            sfc_Moretmp = calculate_theta_and_more([tmp_sfc_temp],[tmp_sfc_pres],\\\n",
    "                                       RH=[tmp_sfc_rh],use_T_K=True,\\\n",
    "                                      sat_pres_formula='Emmanuel')\n",
    "\n",
    "            tmp_sfc_theta = sfc_Moretmp['Theta'][0]\n",
    "            lts = theta_700hpa - tmp_sfc_theta\n",
    "            R_d = 287.058; # gas constant for dry air [J/(kg*K)].\n",
    "            R_v = 461.5; # gas constant for water vapor [J/(kg*K)].\n",
    "            c_p = 1005.7; # +- 2.5 [J/(kg*K)] - specific heat capacity of dry air at 273K in a constant pressure.\n",
    "            g = 9.81 # gravitational acceleration, m/s^2\n",
    "            \n",
    "            dum_T = Sondetmp['drybulb_temp']\n",
    "            dum_qs = Moretmp['q']*1.e-3\n",
    "            dum_Lv = Moretmp['L_v']\n",
    "            moist_ad_lapse_rate = (g/c_p) * (1 - ( (1 + ( (dum_Lv*dum_qs) / (R_d*dum_T) ) ) / (1 + ( ((dum_Lv**2.)*dum_qs) / (c_p*R_v*(dum_T**2.)) ) ) ) )\n",
    "            #moist_ad_lapse_rate = (g/c_p) * (1 - ( (1+((Moretmp['L_v']*Moretmp['w_s'])/(R_d*Sondetmp['drybulb_temp']))) / (1 + (((Moretmp['L_v']**2.)*Moretmp['w_s'])/(c_p*R_v*(Sondetmp['drybulb_temp']**2.)))) ) ) # K/m\n",
    "            #plt.plot(moist_ad_lapse_rate*1.e3,Sondetmp['alt'])\n",
    "            nearest_val_850hpa,nearest_id_850hpa = find_nearest(Sondetmp['pressure'],850)\n",
    "            #sfc_700hpa_temp_avg = (tmp_sfc_temp + temp_700hpa)/2.\n",
    "            moist_ad_lapse_rate_850 = moist_ad_lapse_rate[nearest_id_850hpa] # K/m\n",
    "            #moist_ad_lapse_rate_850 = moist_ad_lapse_rate_850*1.e3 # K/km\n",
    "            pressure_metpy = Sondetmp['pressure'] * units.hPa\n",
    "            temperature_metpy = Sondetmp['drybulb_temp'] * units.K\n",
    "            rh_metpy = Sondetmp['RH'] * units.percent\n",
    "            dewpoint_metpy = mpcalc.dewpoint_from_relative_humidity(temperature_metpy, rh_metpy)\n",
    "            lcl_pres,lcl_temp = mpcalc.lcl(pressure_metpy[0],temperature_metpy[0],dewpoint_metpy[0])\n",
    "            nearest_lcl_pres,nearest_lcl_pres_id = find_nearest(np.array(pressure_metpy),np.array(lcl_pres))\n",
    "            lcl_z = Sondetmp['alt'][nearest_lcl_pres_id]*1.e3 # m\n",
    "            eis = lts - moist_ad_lapse_rate_850*(z_700hpa-lcl_z)\n",
    "            \n",
    "            #if False:\n",
    "            if True:\n",
    "                print('eis:',eis,'K')\n",
    "                print('lts:',lts,'K')\n",
    "                print('lcl_z:',lcl_z,'m')\n",
    "                print('z_700hpa:',z_700hpa,'m')\n",
    "                print('moist_ad_lapse_rate_850:',moist_ad_lapse_rate_850,'K/m')\n",
    "                print(' ')\n",
    "            #print(aaa)\n",
    "            \n",
    "            \n",
    "            native_sonde_dict[str(int(jj+1))] = {}\n",
    "            native_sonde_dict[str(int(jj+1))]['temperature'] = Sondetmp['drybulb_temp']\n",
    "            native_sonde_dict[str(int(jj+1))]['pressure'] = Sondetmp['pressure']\n",
    "            native_sonde_dict[str(int(jj+1))]['rh'] = Sondetmp['RH']\n",
    "            native_sonde_dict[str(int(jj+1))]['u'] = Sondetmp['u_wind']\n",
    "            native_sonde_dict[str(int(jj+1))]['v'] = Sondetmp['v_wind']\n",
    "            native_sonde_dict[str(int(jj+1))]['wind_speed'] = Sondetmp['wind_speed']\n",
    "            native_sonde_dict[str(int(jj+1))]['wind_dir'] = Sondetmp['wind_direction']\n",
    "            native_sonde_dict[str(int(jj+1))]['height'] = Sondetmp['alt']*1.e3\n",
    "            native_sonde_dict[str(int(jj+1))]['time_dt_long'] = Sondetmp['time']\n",
    "\n",
    "\n",
    "            native_sonde_dict[str(int(jj+1))]['q'] = Moretmp['q']\n",
    "            native_sonde_dict[str(int(jj+1))]['theta'] = Moretmp['Theta']\n",
    "            native_sonde_dict[str(int(jj+1))]['theta_e'] = Moretmp['Theta_e']\n",
    "            native_sonde_dict[str(int(jj+1))]['rh_i'] = Moretmp['RH_i']\n",
    "            native_sonde_dict[str(int(jj+1))]['w_s'] = Moretmp['L_v']\n",
    "            native_sonde_dict[str(int(jj+1))]['e'] = Moretmp['e']\n",
    "            native_sonde_dict[str(int(jj+1))]['time_dt'] = current_sonde_time\n",
    "            native_sonde_dict[str(int(jj+1))]['cluster_id'] = current_cluster_id\n",
    "            native_sonde_dict[str(int(jj+1))]['eis'] = eis\n",
    "            native_sonde_dict[str(int(jj+1))]['lts'] = lts\n",
    "            native_sonde_dict[str(int(jj+1))]['lcl'] = lcl_z\n",
    "            \n",
    "    if False:        \n",
    "        for jj in range(len(sonde_flags)):\n",
    "            if sonde_flags[jj]:\n",
    "                fig = plt.figure(figsize=(18,9))\n",
    "                dum_keys = ['temperature','rh','rh_i','theta','theta_e','pressure','wind_speed','wind_dir','u','v','q','w_s','e']\n",
    "                for ii in range(len(dum_keys)):\n",
    "                    dumax = fig.add_subplot(2,8,ii+1)\n",
    "                    dumax.plot(native_sonde_dict[str(int(jj+1))][dum_keys[ii]],native_sonde_dict[str(int(jj+1))]['height']*1.e-3,c='k',lw=2)\n",
    "                    dumax.set_ylabel('Height [km]',fontsize=14)\n",
    "                    dumax.set_xlabel(dum_keys[ii],fontsize=14)\n",
    "                    dumax.tick_params(labelsize=14)\n",
    "                    dumax.grid(True)\n",
    "                    plt.subplots_adjust(wspace=0.5,top=0.925)\n",
    "                    plt.suptitle(native_sonde_dict[str(int(jj+1))]['time_dt'],fontsize=24)\n",
    "                plt.show()\n",
    "                plt.close()\n",
    "    # We have a \"native\" sonde dict with the original soundings\n",
    "    # Now calculate a few things\n",
    "    if np.all(sonde_flags is not False):\n",
    "        sonde_present_flag = True\n",
    "    else:\n",
    "        sonde_present_flag = False\n",
    "    #return sonde_present_flag, native_sonde_dict\n",
    "    return sonde_present_flag, native_sonde_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9af2595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    eis_arr = []\n",
    "    lts_arr = []\n",
    "    time_arr = []\n",
    "    target_date = datetime.datetime(2016,5,23)\n",
    "    for in_date in basta_dates_dt:\n",
    "        #print(in_date)\n",
    "        native_sonde_present_flag, native_sonde_out_dict = process_native_sondes([in_date],sonde_dates_dt,sonde_times_dt,sonde_files,cluster_ids,cluster_times_dt)\n",
    "        keys = list(native_sonde_out_dict.keys())\n",
    "        for ii in range(len(keys)):\n",
    "           # print(keys[ii])\n",
    "            if native_sonde_out_dict[keys[ii]] is not None:\n",
    "                eis_arr.append(native_sonde_out_dict[keys[ii]]['eis'])\n",
    "                lts_arr.append(native_sonde_out_dict[keys[ii]]['lts'])\n",
    "                time_arr.append(native_sonde_out_dict[keys[ii]]['time_dt'])\n",
    "        #print(aaa)\n",
    "    time_arr = np.array(time_arr)\n",
    "    eis_arr = np.array(eis_arr)\n",
    "    lts_arr = np.array(lts_arr)\n",
    "    # remove duplicate values\n",
    "    dum,dumid = np.unique(time_arr,return_index=True)\n",
    "    time_arr = time_arr[dumid]\n",
    "    eis_arr = eis_arr[dumid]\n",
    "    lts_arr = lts_arr[dumid]\n",
    "    \n",
    "    sns.set_theme()\n",
    "    #sns.set_style('dark')\n",
    "    sns.set_style('ticks')\n",
    "    sns.set(rc={'axes.facecolor':'lavender','axes.edgecolor': 'black','grid.color':'white'})\n",
    "    sns.set_context('talk') \n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    ax1.grid(True)\n",
    "    Fontsize=16\n",
    "    ax1.set_xlabel('LTS [K]',fontsize=Fontsize)\n",
    "    ax1.set_ylabel('EIS [K]',fontsize=Fontsize)\n",
    "    ax1.tick_params(labelsize=Fontsize)\n",
    "    ax1.scatter(lts_arr,eis_arr,s=10,c='royalblue')\n",
    "    ax1.set_xlim(0,25)\n",
    "    ax1.set_ylim(-5,25)\n",
    "    ax1.plot([0,25],[0,25],lw=3,c='black',ls='dashed')\n",
    "    plt.show()\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcc31fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_optics(date,optics_dates_dt,optics_files,avg_bool,basta_time_ts):\n",
    "\n",
    "    tmpid = np.where(optics_dates_dt == date)\n",
    "    if np.size(tmpid) == 0.:\n",
    "        optics_present_flag = False\n",
    "        optics_dict = None\n",
    "        return optics_present_flag,optics_dict\n",
    "    elif np.size(tmpid) > 0.:\n",
    "        optics_present_flag = True\n",
    "        tmpid = tmpid[0][0]\n",
    "        current_optics_file = optics_files[tmpid]\n",
    "        current_optics_date = optics_dates_dt[tmpid]    \n",
    "\n",
    "        ncfile = xarray.open_dataset(current_optics_file,decode_times=False)\n",
    "        base_time = ncfile['base_time'].values\n",
    "        time_offset = ncfile['time_offset'].values\n",
    "        qc_time = ncfile['qc_time'].values\n",
    "        tau_inst = ncfile['optical_depth_instantaneous'].values\n",
    "        qc_tau_inst = ncfile['qc_optical_depth_instantaneous'].values\n",
    "        reff_inst = ncfile['effective_radius_instantaneous'].values\n",
    "        qc_reff_inst = ncfile['qc_effective_radius_instantaneous'].values\n",
    "        tau_avg = ncfile['optical_depth_instantaneous'].values\n",
    "        qc_tau_avg = ncfile['qc_optical_depth_average'].values\n",
    "        reff_avg = ncfile['effective_radius_average'].values\n",
    "        qc_reff_avg = ncfile['qc_effective_radius_average'].values\n",
    "        trans1 = ncfile['total_transmittance_filter1'].values\n",
    "        trans2 = ncfile['total_transmittance_filter2'].values\n",
    "        trans3 = ncfile['total_transmittance_filter3'].values\n",
    "        trans4 = ncfile['total_transmittance_filter4'].values\n",
    "        trans5 = ncfile['total_transmittance_filter5'].values\n",
    "        source_lwp = ncfile['source_lwp'].values\n",
    "        lwp = ncfile['lwp'].values\n",
    "        qc_lwp = ncfile['qc_lwp'].values\n",
    "        pwv = ncfile['pwv'].values\n",
    "        qc_pwv = ncfile['qc_pwv'].values\n",
    "        cf = ncfile['cloudfraction'].values\n",
    "        qc_cf = ncfile['qc_cloudfraction'].values\n",
    "        ncfile.close()\n",
    "        time_ts = base_time + time_offset\n",
    "        time_dt = np.array([toDatetime(time_ts[dd]) for dd in range(len(time_ts))])\n",
    "        \n",
    "        tau_inst_interp = np.interp(basta_time_ts,time_ts,tau_inst)\n",
    "        tau_avg_interp = np.interp(basta_time_ts,time_ts,tau_avg)\n",
    "        trans1_interp = np.interp(basta_time_ts,time_ts,trans1)\n",
    "        trans2_interp = np.interp(basta_time_ts,time_ts,trans2)\n",
    "        trans3_interp = np.interp(basta_time_ts,time_ts,trans3)\n",
    "        trans4_interp = np.interp(basta_time_ts,time_ts,trans4)\n",
    "        trans5_interp = np.interp(basta_time_ts,time_ts,trans5)\n",
    "        ref_inst_interp = np.interp(basta_time_ts,time_ts,reff_inst)\n",
    "        reff_avg_interp = np.interp(basta_time_ts,time_ts,reff_avg)\n",
    "        lwp_interp = np.interp(basta_time_ts,time_ts,lwp)\n",
    "        cf_interp = np.interp(basta_time_ts,time_ts,cf)\n",
    "        \n",
    "        optics_dict = {'tau_inst':tau_inst_interp,\\\n",
    "                       'tau_avg':tau_avg_interp,\\\n",
    "                       'reff_inst':tau_avg_interp,\\\n",
    "                       'reff_avg':tau_avg_interp,\\\n",
    "                       'trans1':trans1_interp,\\\n",
    "                       'trans2':trans2_interp,\\\n",
    "                       'trans3':trans3_interp,\\\n",
    "                       'trans4':trans4_interp,\\\n",
    "                       'trans5':trans5_interp,\\\n",
    "                       'cloud_fraction':cf_interp,\\\n",
    "                       'lwp':lwp_interp,\\\n",
    "                       'native_tau_inst':tau_inst,\\\n",
    "                       'native_tau_avg':tau_avg,\\\n",
    "                       'native_trans1':trans1,\\\n",
    "                       'native_trans2':trans2,\\\n",
    "                       'native_trans3':trans3,\\\n",
    "                       'native_trans4':trans4,\\\n",
    "                       'native_trans5':trans5,\\\n",
    "                       'native_reff_inst':reff_inst,\\\n",
    "                       'native_reff_avg':reff_avg,\\\n",
    "                       'native_lwp':lwp,\\\n",
    "                       'native_lwp':pwv,\\\n",
    "                       'native_source_lwp':source_lwp,\\\n",
    "                       'native_time_dt':time_dt,\\\n",
    "                       'native_time_ts':time_ts,\\\n",
    "                       'native_cloud_fraction':cf,\\\n",
    "                      }\n",
    "        \n",
    "        return optics_present_flag,optics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b31c9172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp_sondes(date,sonde_dates_dt,sonde_times_dt,sonde_files,basta_times_dt,basta_height,cluster_ids,cluster_times_dt):\n",
    "    \n",
    "\n",
    "\n",
    "    # Get current_date\n",
    "    sonde_id = np.where(sonde_dates_dt == date)[0]\n",
    "\n",
    "    # Pull out 3 potential soundings (1 on previous day, 2 on current_day)\n",
    "    \n",
    "    # The interpolation will work as follows:\n",
    "    #   If there are 3 available soundings, times before 12 UTC will be\n",
    "    #   linearly interpolated onto constant altitude levels between the\n",
    "    #   12 UTC sounding and the previous 00 UTC sounding. Times after 12\n",
    "    #   UTC are interpolated between 12 UTC and the 00 UTC sounding, which\n",
    "    #  is generally at 2315 UTC. If there is a sounding at ~2315 UTC, the\n",
    "    #  rest of the day is considerd to be consant with that sounding.\n",
    "    \n",
    "    date = date[0]\n",
    "    \n",
    "    target_time_1 = datetime.datetime(date.year,date.month,date.day,0)\n",
    "    target_time_2 = datetime.datetime(date.year,date.month,date.day,12)\n",
    "    tmp_time_delta = datetime.timedelta(days=1)\n",
    "    target_time_3 = datetime.datetime(date.year,date.month,date.day,0) + tmp_time_delta\n",
    "    \n",
    "    sonde_times_dt = np.array(sonde_times_dt)\n",
    "    \n",
    "    tmpid = np.where((sonde_times_dt > (target_time_1 - datetime.timedelta(hours=2))) & (sonde_times_dt < (target_time_1 + datetime.timedelta(hours=2))))\n",
    "    if np.size(tmpid) > 0:\n",
    "        sonde_1_id = tmpid[0][0]\n",
    "        sonde_1_flag = True\n",
    "        sonde_1_time = sonde_times_dt[sonde_1_id]\n",
    "    else:\n",
    "        sonde_1_flag = False\n",
    "        sonde_1_id = -999.\n",
    "        sonde_1_time = -999.\n",
    "    tmpid = np.where((sonde_times_dt > (target_time_2 - datetime.timedelta(hours=2))) & (sonde_times_dt < (target_time_2 + datetime.timedelta(hours=2))))\n",
    "    if np.size(tmpid) > 0:\n",
    "        sonde_2_id = tmpid[0][0]\n",
    "        sonde_2_flag = True\n",
    "        sonde_2_time = sonde_times_dt[sonde_2_id]\n",
    "    else:\n",
    "        sonde_2_flag = False\n",
    "        sonde_2_id = -999.\n",
    "        sonde_2_time = -999.\n",
    "    tmpid = np.where((sonde_times_dt > (target_time_3 - datetime.timedelta(hours=2))) & (sonde_times_dt < (target_time_3 + datetime.timedelta(hours=2))))\n",
    "    if np.size(tmpid) > 0:\n",
    "        sonde_3_id = tmpid[0][0]\n",
    "        sonde_3_flag = True\n",
    "        sonde_3_time = sonde_times_dt[sonde_3_id]\n",
    "    else:\n",
    "        sonde_3_flag = False \n",
    "        sonde_3_id = -999.\n",
    "        sonde_3_time = -999.\n",
    "    \n",
    "    sonde_flags = [sonde_1_flag,sonde_2_flag,sonde_3_flag]\n",
    "    sonde_ids = [sonde_1_id,sonde_2_id,sonde_3_id]   \n",
    "\n",
    "    sonde_dict = {}\n",
    "    for jj in range(len(sonde_flags)):\n",
    "        if not sonde_flags[jj]:\n",
    "            sonde_dict[str(int(jj+1))] = None\n",
    "            continue\n",
    "        elif sonde_flags[jj]:\n",
    "            current_sonde_id = sonde_ids[jj]\n",
    "            current_sonde_file = sonde_files[current_sonde_id]\n",
    "            current_sonde_time = sonde_times_dt[current_sonde_id]\n",
    "            dumid = np.where(cluster_times_dt == current_sonde_time)\n",
    "            if np.size(dumid) > 0.:\n",
    "                current_cluster_id = cluster_ids[dumid[0][0]]\n",
    "            else:\n",
    "                current_cluster_id = None\n",
    "            \n",
    "            current_sonde_file = current_sonde_file.split('/')[-1]\n",
    "            path = '/mnt/raid/mwstanfo/micre_data/micre_soundings/'\n",
    "            file_size = os.stat(path+current_sonde_file).st_size/1.e3\n",
    "            fstruct = fs(current_sonde_file,path,file_size)\n",
    "            Sondetmp = load_sonde_data(fstruct)         \n",
    "\n",
    "            max_alt = np.max(Sondetmp['alt'])\n",
    "            if max_alt < 10.:\n",
    "                print('Sonde failed to reach 10 km. Therefore omitting this sounding.')\n",
    "                sonde_dict[str(int(jj+1))] = None\n",
    "                sonde_flags[jj] = False\n",
    "                continue\n",
    "            else:\n",
    "                pass    \n",
    "    \n",
    "            sonde_dict[str(int(jj+1))] = {}\n",
    "            sonde_dict[str(int(jj+1))]['temperature'] = Sondetmp['drybulb_temp']    \n",
    "            sonde_dict[str(int(jj+1))]['rh'] = Sondetmp['RH']    \n",
    "            sonde_dict[str(int(jj+1))]['height'] = Sondetmp['alt']*1.e3\n",
    "            sonde_dict[str(int(jj+1))]['time'] = current_sonde_time\n",
    "            sonde_dict[str(int(jj+1))]['cluster_id'] = current_cluster_id\n",
    "    \n",
    "    \n",
    "    num_times = len(basta_times_dt)\n",
    "    num_heights = len(basta_height)\n",
    "    basta_times_ts = np.array([toTimestamp(basta_times_dt[dd]) for dd in range(len(basta_times_dt))])\n",
    "\n",
    "    dumid = np.where(sonde_flags)[0]\n",
    "    num_current_soundings = np.size(dumid)\n",
    "    \n",
    "    print('# of current soundings:',num_current_soundings)\n",
    "    if num_current_soundings == 0.:\n",
    "        interp_sonde_present_flag = False\n",
    "        interp_sonde_dict = None\n",
    "        return interp_sonde_present_flag, interp_sonde_dict\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    interp_sonde_present_flag = True\n",
    "    interp_sonde_dict = None\n",
    "    \n",
    "    temp_arr = []\n",
    "    rh_arr = []\n",
    "    height_arr = []\n",
    "    time_arr = []\n",
    "    cluster_id_arr = []\n",
    "    for jj in range(len(sonde_flags)):\n",
    "        if sonde_flags[jj]:\n",
    "            temp_arr.append(sonde_dict[str(int(jj+1))]['temperature'])\n",
    "            rh_arr.append(sonde_dict[str(int(jj+1))]['rh'])\n",
    "            height_arr.append(sonde_dict[str(int(jj+1))]['height'])\n",
    "            time_arr.append(sonde_dict[str(int(jj+1))]['time'])\n",
    "            cluster_id_arr.append(sonde_dict[str(int(jj+1))]['cluster_id'])\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    temp_interp_arr = []\n",
    "    rh_interp_arr = []\n",
    "    for jj in range(num_current_soundings):\n",
    "        temp_interp_arr.append(np.interp(basta_height,height_arr[jj],temp_arr[jj]))\n",
    "        rh_interp_arr.append(np.interp(basta_height,height_arr[jj],rh_arr[jj]))\n",
    "        \n",
    "    temp_interp_arr = np.array(temp_interp_arr)\n",
    "    rh_interp_arr = np.array(rh_interp_arr)\n",
    "    time_arr = np.array(time_arr)\n",
    "    time_arr_ts = np.array([toTimestamp(time_arr[dd]) for dd in range(len(time_arr))])\n",
    "    cluster_id_arr = np.array(cluster_id_arr)\n",
    "    \n",
    "    # check interpolation\n",
    "    if False:\n",
    "        fig = plt.figure(figsize=(8,8))\n",
    "        ax1 = fig.add_subplot(111)\n",
    "        ax1.plot(temp_interp_arr[1],basta_height,c='b',lw=4)\n",
    "        ax1.plot(temp_arr[1],height_arr[1],c='darkorange',ls='dotted',lw=4)\n",
    "        ax1.set_ylim(0,np.max(basta_height))\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "    temp_interp = []\n",
    "    rh_interp = []\n",
    "    for kk in range(num_heights):\n",
    "        temp_interp.append(np.interp(basta_times_ts,time_arr_ts,temp_interp_arr[:,kk],\\\n",
    "                                                       left=temp_interp_arr[0,kk],\\\n",
    "                                                       right=temp_interp_arr[-1,kk]))        \n",
    "        rh_interp.append(np.interp(basta_times_ts,time_arr_ts,rh_interp_arr[:,kk],\\\n",
    "                                                       left=rh_interp_arr[0,kk],\\\n",
    "                                                       right=rh_interp_arr[-1,kk])) \n",
    "\n",
    "\n",
    "    temp_interp = np.array(temp_interp)\n",
    "    rh_interp = np.array(rh_interp)\n",
    "    \n",
    "    if False:\n",
    "        fig = plt.figure(figsize=(8,6))\n",
    "        ax1= fig.add_subplot(211)\n",
    "        ax2= fig.add_subplot(212)\n",
    "        \n",
    "        dumplot = ax1.contourf(basta_times_dt,basta_height,temp_interp-273.15,cmap='RdYlBu_r')\n",
    "        cbar = fig.colorbar(dumplot,ax=ax1)\n",
    "        cbar.ax.set_ylabel('Temperature [$^{\\\\circ}$]')\n",
    "        dumplot = ax2.contourf(basta_times_dt,basta_height,rh_interp,cmap='ocean')\n",
    "        cbar = fig.colorbar(dumplot,ax=ax2)\n",
    "        cbar.ax.set_ylabel('RH [%]')\n",
    "                        \n",
    "        ax1.grid(True)\n",
    "        ax2.grid(True)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    \n",
    "\n",
    "    # calculate time to nearest sounding\n",
    "    time_to_nearest_sounding = []\n",
    "    nearest_cluster_id = []\n",
    "    # Now calculate time to nearest sounding using timedeltas\n",
    "    for ttt in range(len(basta_times_dt)):\n",
    "        single_time_ts = toTimestamp(basta_times_dt[ttt])\n",
    "\n",
    "        diff_arr = np.abs(single_time_ts - time_arr_ts)\n",
    "        dum_min = np.min(diff_arr)\n",
    "        time_to_nearest_sounding.append(dum_min)\n",
    "        \n",
    "        # Find nearest sounding\n",
    "        nearest_val,nearest_id = find_nearest(time_arr_ts,single_time_ts)\n",
    "        nearest_cluster_id.append(cluster_id_arr[nearest_id])\n",
    "    time_to_nearest_sounding = np.array(time_to_nearest_sounding)\n",
    "    nearest_cluster_id = np.array(nearest_cluster_id)\n",
    "    \n",
    "    # Boolean plot to check cluster id \"interpolation\"\n",
    "    if False:\n",
    "        fig = plt.figure(figsize=(12,4))\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.plot(basta_times_dt,nearest_cluster_id)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "                                  \n",
    "                                \n",
    "                        \n",
    "    interp_sonde_dict = {'temperature':temp_interp,'rh':rh_interp,'seconds_to_nearest_sounding':time_to_nearest_sounding,'nearest_cluster_id':nearest_cluster_id}\n",
    "    \n",
    "    return interp_sonde_present_flag,interp_sonde_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "edb937df-fb99-4cd4-8dde-fcfa1d627bc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for date in basta_dates_dt[13:]:\n",
    "#     in_date = [date]\n",
    "#     basta_present_flag,merged_dict = merge_instruments(in_date,basta_files,basta_dates_dt,False,arm_ceil_dates_dt,arm_ceil_files,aad_ceil_dates_dt,aad_ceil_files,sonde_dates_dt,sonde_files)\n",
    "#     print(aaaa)\n",
    "#     if basta_present_flag:\n",
    "#         save_path = '/mnt/raid/mwstanfo/micre/merged_instrument_files/'\n",
    "#         dum_time_str = in_date[0].strftime('%Y%m%d')\n",
    "#         out_pkl_file = save_path+'merged_instruments_{}_v2.p'.format(dum_time_str)\n",
    "#         pickle.dump(merged_dict,open(out_pkl_file,\"wb\"))\n",
    "#         print(aaaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1c8bc97-bc90-40d7-b1fc-e2ffeab0d9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================================\n",
    "# Function to process basta data\n",
    "#\n",
    "# Inputs: date -- from basta_dates_dt\n",
    "#         avg_bool -- boolean to perform averaging\n",
    "#==================================================\n",
    "def process_basta(date,basta_dates_dt,basta_files,avg_bool):\n",
    "    # grab date\n",
    "    dumid = np.where(basta_dates_dt == date[0])\n",
    "    dumid = dumid[0][0]\n",
    "    \n",
    "    # read in file\n",
    "    ncfile = xarray.open_dataset(basta_files[dumid],decode_times=False)\n",
    "    basta_time_dims = ncfile.dims['time'] # will be variable according to up-time\n",
    "    basta_height_dims = ncfile.dims['height'] # should always be 480\n",
    "    basta_ref = np.array(ncfile['reflectivity'].copy())\n",
    "    basta_vel = np.array(ncfile['velocity'].copy())\n",
    "    basta_flag = np.array(ncfile['flag'].copy())\n",
    "    basta_flag_coupling = np.array(ncfile['flag_coupling'].copy()) # 0: no coupling (good); 1: coupling (bad)\n",
    "    basta_noise_level = np.array(ncfile['noise_level'].copy()) # 0: good data; 1-9: bad data; -1: no data\n",
    "    basta_time_sec_since_00Z = np.array(ncfile['time'].copy())\n",
    "    basta_height = np.array(ncfile['height'].copy()) # 25-m resolution beginning at 12.5 m (mid-bin)\n",
    "    ### ends at 11987.5 m, so 12 km\n",
    "    ncfile.close()\n",
    "    \n",
    "    tmp_basta_time_ts = toTimestamp(datetime.datetime(date[0].year,\\\n",
    "                                       date[0].month,\\\n",
    "                                       date[0].day))\n",
    "    tmp_basta_time_ts = tmp_basta_time_ts + basta_time_sec_since_00Z\n",
    "    basta_time_dt = [toDatetime(tmp_basta_time_ts[dd]) for dd in range(len(tmp_basta_time_ts))]\n",
    "    basta_time_dt = np.array(basta_time_dt) # holds the BASTA time array for the current file.\n",
    "    \n",
    "    # Need to ensure BASTA times are stricty increasing.\n",
    "    # This is a rare occurrence--only 2 days. Informed\n",
    "    # Alain Protat, but just omitting these cases.\n",
    "    diff = np.diff(tmp_basta_time_ts)\n",
    "\n",
    "    if np.min(diff) < 0.:\n",
    "        #raise RuntimeError('BASTA times are not strictly increasing.')\n",
    "        basta_present_flag = False\n",
    "        basta_out_dict = None\n",
    "        return basta_present_flag, basta_out_dict\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    basta_present_flag = True\n",
    "    \n",
    "    #------------------------------------------------------\n",
    "    # For some of the files, the date after the current one\n",
    "    # holds the last hour of the day. In these cases, will\n",
    "    # need to pull in the following day.\n",
    "    #------------------------------------------------------\n",
    "    \n",
    "    # Check first time of following file and grab times and associated\n",
    "    # variables where the DAY matches that of the current BASTA day.\n",
    "    # Grab next file\n",
    "    if (date[0] != datetime.datetime(2016,4,2)) and (date[0] != datetime.datetime(2017,3,17)):\n",
    "\n",
    "        ncfile = xarray.open_dataset(basta_files[dumid+1],decode_times=False)\n",
    "\n",
    "        after_basta_time_sec_since_00Z = np.array(ncfile['time'].copy())\n",
    "        ncfile.close()\n",
    "        tmp_basta_time_ts = toTimestamp(datetime.datetime(basta_dates_dt[dumid+1].year,\\\n",
    "                                           basta_dates_dt[dumid+1].month,\\\n",
    "                                           basta_dates_dt[dumid+1].day))\n",
    "\n",
    "        tmp_basta_time_ts = tmp_basta_time_ts + after_basta_time_sec_since_00Z\n",
    "        after_basta_time_dt = [toDatetime(tmp_basta_time_ts[dd]) for dd in range(len(tmp_basta_time_ts))]\n",
    "        after_basta_date_dt = [datetime.datetime(after_basta_time_dt[dd].year,\\\n",
    "                                                after_basta_time_dt[dd].month,\\\n",
    "                                                after_basta_time_dt[dd].day) for dd in range(len(after_basta_time_dt))]\n",
    "        after_basta_time_dt = np.array(after_basta_time_dt) # holds the BASTA time array for the after file.\n",
    "        after_basta_date_dt = np.array(after_basta_date_dt) # holds the BASTA date array for the after file.\n",
    "        \n",
    "        # check to see if any of the dates in the after file equal the date on the current file\n",
    "        date = date[0]\n",
    "        tmpid = np.where(after_basta_date_dt == date)\n",
    "        if np.size(tmpid) > 0.:\n",
    "            # now open back up after file and add indices in after file with\n",
    "            # same date as current file to the current BASTA arrays\n",
    "            ncfile = xarray.open_dataset(basta_files[dumid+1],decode_times=False)\n",
    "            after_basta_ref = np.array(ncfile['reflectivity'].copy())\n",
    "            after_basta_vel = np.array(ncfile['velocity'].copy())\n",
    "            after_basta_flag = np.array(ncfile['flag'].copy())\n",
    "            after_basta_flag_coupling = np.array(ncfile['flag_coupling'].copy()) # 0: no coupling (good); 1: coupling (bad)\n",
    "            after_basta_noise_level = np.array(ncfile['noise_level'].copy()) # 0: good data; 1-9: bad data; -1: no data\n",
    "            ncfile.close()  \n",
    "            \n",
    "            # now concatenate arrays\n",
    "            basta_time_dt = np.concatenate((basta_time_dt,after_basta_time_dt[tmpid]))\n",
    "            basta_ref = np.concatenate((basta_ref,np.squeeze(after_basta_ref[:,tmpid])),axis=1)\n",
    "            basta_vel = np.concatenate((basta_vel,np.squeeze(after_basta_vel[:,tmpid])),axis=1)\n",
    "            basta_flag = np.concatenate((basta_flag,np.squeeze(after_basta_flag[:,tmpid])),axis=1)\n",
    "            basta_flag_coupling = np.concatenate((basta_flag_coupling,after_basta_flag_coupling[tmpid]),axis=0)\n",
    "            basta_noise_level = np.concatenate((basta_noise_level,after_basta_noise_level[tmpid]),axis=0)\n",
    "            \n",
    "\n",
    "                \n",
    "    # Because the current date BASTA file sometimes start at 23Z on the day prior, also need to\n",
    "    # limit the current file to encompass only times on the current date (i.e., need to limit\n",
    "    # the current date variables, filtering out those from 23Z-00Z on the previous date)\n",
    "    basta_date_dt = np.array([datetime.datetime(basta_time_dt[dd].year,\\\n",
    "                                                basta_time_dt[dd].month,\\\n",
    "                                                basta_time_dt[dd].day) for dd in range(len(basta_time_dt))])\n",
    "    \n",
    "    # Check to see if any of the dates in the current file equal the before date\n",
    "    if (date != datetime.datetime(2016,4,2)) and (date != datetime.datetime(2017,3,17)):\n",
    "        tmpid = np.where(basta_date_dt != date)\n",
    "        if np.size(tmpid) > 0.:\n",
    "            # limit arrays\n",
    "            tmpid = np.where(basta_date_dt == date)\n",
    "            basta_time_dt = basta_time_dt[tmpid]\n",
    "            basta_flag_coupling = basta_flag_coupling[tmpid]\n",
    "            basta_flag = basta_flag[:,tmpid]\n",
    "            basta_ref = basta_ref[:,tmpid]\n",
    "            basta_vel = basta_vel[:,tmpid]\n",
    "            basta_noise_level = basta_noise_level[tmpid]\n",
    "\n",
    "    \n",
    "    basta_ref = np.squeeze(basta_ref)\n",
    "    basta_vel = np.squeeze(basta_vel)\n",
    "    basta_flag = np.squeeze(basta_flag)\n",
    "    basta_flag_coupling = np.squeeze(basta_flag_coupling)\n",
    "    basta_noise_level = np.squeeze(basta_noise_level)         \n",
    "        \n",
    "        \n",
    "    #-----------------------------------------\n",
    "    #-----------------------------------------\n",
    "    #-----------------------------------------\n",
    "    # Create a series of flags that will indicate\n",
    "    # whether or not a cloud is present\n",
    "    # \n",
    "    # basta_flag == 1 means radar is working\n",
    "    # properly but there is no data. These values\n",
    "    # are flagged as -999. When basta_flag > 0.\n",
    "    # or when basta_flag_coupling > 0., we will\n",
    "    # assign these values as NaNs. For values\n",
    "    # below the theoretical minimum detectable signal,\n",
    "    # we will assign these as -999. as well. Values\n",
    "    # up to 137.5 m will be flagged as NaNs, indicating\n",
    "    # bad data.\n",
    "    #-----------------------------------------\n",
    "    #-----------------------------------------\n",
    "    #-----------------------------------------\n",
    "    \n",
    "    bad_radar_data_flag = np.zeros(len(basta_time_dt))\n",
    "    min_basta_loc = 6\n",
    "    # create array that is the minimum detectable signal as a function of altitude\n",
    "    Z_min_1km = -36.\n",
    "    ref_range = 1000.\n",
    "    Z_min = Z_min_1km + 20.*np.log10(basta_height) - 20.*np.log10(ref_range)\n",
    "    Z_min[0] = -999.    \n",
    "\n",
    "    # NaN out values up to 137.5 m due to surface clutter\n",
    "    basta_ref[0:min_basta_loc,:] = np.nan\n",
    "    basta_vel[0:min_basta_loc,:] = np.nan\n",
    "    # We will also assign all basta_flag values up to 137.5 m\n",
    "    # as -1. Currently basta_flag == -1 only up to 87.5 m, so we\n",
    "    # want to adjust this.\n",
    "    basta_flag[0:min_basta_loc,:] = -1\n",
    "            \n",
    "        \n",
    "    # Set values below the minimum detectable signal to -999.\n",
    "    for ttt in range(len(basta_time_dt)):\n",
    "        dumid = np.where(basta_ref[:,ttt] < Z_min)\n",
    "        if np.size(dumid) > 0.:\n",
    "            basta_ref[dumid,ttt] = -999.\n",
    "            basta_vel[dumid,ttt] = -999.\n",
    "            basta_flag[dumid,ttt] = -1\n",
    "    \n",
    "    dumid = np.where(basta_flag_coupling == 1.)\n",
    "    if np.size(dumid) > 0.:\n",
    "        basta_ref[:,dumid] = np.nan\n",
    "        basta_vel[:,dumid] = np.nan\n",
    "        bad_radar_data_flag[dumid] = 1\n",
    "        \n",
    "    for ttt in range(len(basta_time_dt)):\n",
    "        single_time_basta_flag = basta_flag[:,ttt]\n",
    "        dumid = np.where(single_time_basta_flag > 0.)\n",
    "        if np.size(dumid) > 0.:\n",
    "            basta_ref[dumid,ttt] = np.nan\n",
    "            basta_vel[dumid,ttt] = np.nan\n",
    "        if np.all(single_time_basta_flag > 0.):\n",
    "            bad_radar_data_flag[ttt] = 1           \n",
    "    \n",
    "    basta_time_ts = np.array([toTimestamp(basta_time_dt[dd]) for dd in range(len(basta_time_dt))])\n",
    "    basta_out_dict = {'time_dt':basta_time_dt,\\\n",
    "                      'time_ts':basta_time_ts,\\\n",
    "                      'ref':basta_ref,\\\n",
    "                      'vel':basta_vel,\\\n",
    "                      'height':basta_height,\\\n",
    "                      'bad_radar_data_flag':bad_radar_data_flag,\\\n",
    "                      'flag':basta_flag,\\\n",
    "                     }\n",
    "    \n",
    "    return basta_present_flag,basta_out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdbc2768-1094-4317-9cb8-6535fa3ea487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_arm_ceil(date,arm_ceil_dates_dt,arm_ceil_files,avg_bool,basta_height,basta_time_ts,interp_backscatter=False):\n",
    "    tmpid = np.where(arm_ceil_dates_dt == date)\n",
    "    if np.size(tmpid) == 0.:\n",
    "        arm_ceil_present_flag = False\n",
    "        arm_ceil_out_dict = None\n",
    "        return arm_ceil_present_flag, arm_ceil_out_dict\n",
    "    elif np.size(tmpid) > 0.:        \n",
    "        arm_ceil_present_flag = True\n",
    "        tmpid = tmpid[0][0]\n",
    "        current_ceil_file = arm_ceil_files[tmpid]\n",
    "        ncfile = xarray.open_dataset(current_ceil_file,decode_times=False)\n",
    "        ceil_dims = ncfile.dims\n",
    "        ceil_base_time = np.array(ncfile['base_time'].copy())        \n",
    "        ceil_num_times = ceil_dims['time']\n",
    "        ceil_time_offset = np.array(ncfile['time_offset'].copy())\n",
    "        ceil_cbh_1 = np.array(ncfile['first_cbh'].copy())\n",
    "        ceil_qc_cbh_1 = np.array(ncfile['qc_first_cbh'].copy())\n",
    "        ceil_cbh_2 = np.array(ncfile['second_cbh'].copy())\n",
    "        ceil_qc_cbh_2 = np.array(ncfile['qc_second_cbh'].copy())\n",
    "        ceil_cbh_3 = np.array(ncfile['third_cbh'].copy())\n",
    "        ceil_qc_cbh_3 = np.array(ncfile['qc_third_cbh'].copy())\n",
    "        ceil_backscatter = np.array(ncfile['backscatter'].copy())\n",
    "        ceil_sum_backscatter = np.array(ncfile['sum_backscatter'].copy())\n",
    "        ceil_qc_sum_backscatter = np.array(ncfile['qc_sum_backscatter'].copy())\n",
    "        ceil_detection_status = np.array(ncfile['detection_status'].copy())\n",
    "        ceil_time_ts = [int(ceil_base_time + ceil_time_offset[dd]) for dd in range(ceil_num_times)]\n",
    "        ceil_time_dt = [toDatetime(ceil_time_ts[dd]) for dd in range(ceil_num_times)]    \n",
    "        ceil_range_bounds = np.array(ncfile['range_bounds'].copy())\n",
    "        ceil_range = np.array(ncfile['range'].copy())\n",
    "        ncfile.close()\n",
    "\n",
    "        # qc backscatter\n",
    "        dumxid = np.where(ceil_qc_sum_backscatter > 0)\n",
    "        if np.size(dumxid) > 0.:\n",
    "            #dumxid = np.squeeze(dumxid)\n",
    "            ceil_backscatter[dumxid,:] = np.nan \n",
    "            ceil_sum_backscatter[dumxid,:] = np.nan \n",
    "        ceil_backscatter = ceil_backscatter*1.e-3/10000.  \n",
    "        \n",
    "        ceil_backscatter_log = ceil_backscatter.copy()\n",
    "        dumid = np.where((~np.isnan(ceil_backscatter)) & (ceil_backscatter > 0.) )\n",
    "        ceil_backscatter_log[dumid] = np.log10(ceil_backscatter[dumid])\n",
    "        dumid = np.where(ceil_backscatter == 0.)\n",
    "        ceil_backscatter_log[dumid] = np.nan\n",
    "        dumid = np.where(ceil_backscatter < 0.)\n",
    "        ceil_backscatter_log[dumid] = np.nan\n",
    "        #ceil_backscatter_log[np.isnan(ceil_backscatter_log)] = 0. \n",
    "        ceil_backscatter = ceil_backscatter_log\n",
    "\n",
    "        #------------------------------------------\n",
    "        # Interpolate ceilometer to radar time grid\n",
    "        # using nearest neighbor interpolation. \n",
    "        # This method requires that the nearest\n",
    "        # neighbor be within 15 seconds of the\n",
    "        # radar time grid element.\n",
    "        #------------------------------------------\n",
    "        ceil_time_ts = np.array([toTimestamp(ceil_time_dt[dd]) for dd in range(len(ceil_time_dt))])\n",
    "        basta_bin_edges = np.arange(0,np.max(basta_height)+12.5+25.,25.)\n",
    "        basta_height = np.around(basta_height,2)\n",
    "        basta_time_dt = np.array([toDatetime(basta_time_ts[dd]) for dd in range(len(basta_time_ts))])\n",
    "        ceil_cbh_1_interp = []\n",
    "        ceil_cbh_2_interp = []\n",
    "        ceil_cbh_3_interp = []\n",
    "        ceil_detection_status_interp = []\n",
    "        ceil_cbh_bin_relative_interp = []\n",
    "        for ttt in range(len(basta_time_ts)):\n",
    "            # if here, then good radar data exists\n",
    "            # Now find the nearest in time ceilometer time step to the radar time step\n",
    "            # If the ceilometer is more than 15 seconds away from the the radar time step,\n",
    "            # then we will flag it as missing data (NaN)\n",
    "            nearest_val,nearest_id = find_nearest(ceil_time_ts,basta_time_ts[ttt])\n",
    "            time_diff = np.abs(nearest_val - basta_time_ts[ttt])\n",
    "            target_time_diff = 16\n",
    "            if time_diff <= target_time_diff:\n",
    "                nearest_ceil_cbh_1 = ceil_cbh_1[nearest_id]\n",
    "                nearest_ceil_cbh_2 = ceil_cbh_2[nearest_id]\n",
    "                nearest_ceil_cbh_3 = ceil_cbh_3[nearest_id]\n",
    "                nearest_ceil_detection_status = ceil_detection_status[nearest_id]\n",
    "                ceil_detection_status_interp.append(nearest_ceil_detection_status)\n",
    "\n",
    "                if np.isnan(nearest_ceil_detection_status):\n",
    "                    #ceil_detection_status_interp.append(np.nan)\n",
    "                    ceil_cbh_1_interp.append(np.nan)\n",
    "                    ceil_cbh_2_interp.append(np.nan)\n",
    "                    ceil_cbh_3_interp.append(np.nan)\n",
    "                    ceil_cbh_bin_relative_interp.append(np.nan)\n",
    "                    continue\n",
    "                    \n",
    "                elif (nearest_ceil_detection_status == 5.) or (nearest_ceil_detection_status == 0.):\n",
    "                    ceil_cbh_1_interp.append(-999.)\n",
    "                    ceil_cbh_2_interp.append(-999.)\n",
    "                    ceil_cbh_3_interp.append(-999.)\n",
    "                    ceil_cbh_bin_relative_interp.append(-999.)\n",
    "                    continue\n",
    "                    \n",
    "                elif (nearest_ceil_detection_status == 4.):\n",
    "                    ceil_cbh_1_interp.append(np.nan)\n",
    "                    ceil_cbh_2_interp.append(np.nan)\n",
    "                    ceil_cbh_3_interp.append(np.nan)\n",
    "                    ceil_cbh_bin_relative_interp.append(np.nan)\n",
    "                    continue                    \n",
    "                    \n",
    "                elif (nearest_ceil_detection_status == 1.) or (nearest_ceil_detection_status == 2.) or (nearest_ceil_detection_status == 3.):\n",
    "                    pass\n",
    "                else:\n",
    "                    raise RuntimeError('Something went wrong')\n",
    "\n",
    "                #if np.isnan(nearest_ceil_cbh_1):\n",
    "                #    ceil_cbh_1_interp.append(np.nan)\n",
    "                #    ceil_cbh_2_interp.append(np.nan)\n",
    "                #    ceil_cbh_3_interp.append(np.nan)\n",
    "                #    ceil_cbh_bin_relative_interp.append(np.nan)\n",
    "                #    continue\n",
    "                \n",
    "                if np.isnan(nearest_ceil_cbh_1):\n",
    "                    print(nearest_ceil_cbh_1)\n",
    "                    print(nearest_ceil_detection_status)\n",
    "                    raise RuntimeError('Something went wrong')\n",
    "                    \n",
    "                nearest_val,nearest_id = find_nearest(basta_bin_edges,nearest_ceil_cbh_1)\n",
    "                if nearest_ceil_cbh_1 == nearest_val:\n",
    "                    bin_edges = basta_bin_edges[nearest_id-1:nearest_id+1]\n",
    "                    midbin = (bin_edges[0]+bin_edges[1])/2.\n",
    "                    ceil_cbh_1_interp.append(midbin)\n",
    "                    ceil_cbh_bin_relative_interp.append(1.)\n",
    "                elif nearest_ceil_cbh_1 < nearest_val:\n",
    "                    bin_edges = basta_bin_edges[nearest_id-1:nearest_id+1]\n",
    "                    midbin = (bin_edges[0]+bin_edges[1])/2.\n",
    "                    ceil_cbh_1_interp.append(midbin)\n",
    "                    ceil_cbh_bin_relative_interp.append(0.)\n",
    "                elif nearest_ceil_cbh_1 > nearest_val:\n",
    "                    bin_edges = basta_bin_edges[nearest_id:nearest_id+2]\n",
    "                    midbin = (bin_edges[0]+bin_edges[1])/2.\n",
    "                    ceil_cbh_1_interp.append(midbin)\n",
    "                    ceil_cbh_bin_relative_interp.append(2.)\n",
    "                    \n",
    "                if np.isnan(nearest_ceil_cbh_2):\n",
    "                    ceil_cbh_2_interp.append(np.nan)\n",
    "                else:    \n",
    "                    nearest_val,nearest_id = find_nearest(basta_bin_edges,nearest_ceil_cbh_2)\n",
    "                    if nearest_ceil_cbh_2 == nearest_val:\n",
    "                        bin_edges = basta_bin_edges[nearest_id-1:nearest_id+1]\n",
    "                        midbin = (bin_edges[0]+bin_edges[1])/2.\n",
    "                        ceil_cbh_2_interp.append(midbin)\n",
    "                    elif nearest_ceil_cbh_2 < nearest_val:\n",
    "                        bin_edges = basta_bin_edges[nearest_id-1:nearest_id+1]\n",
    "                        midbin = (bin_edges[0]+bin_edges[1])/2.\n",
    "                        ceil_cbh_2_interp.append(midbin)\n",
    "                    elif nearest_ceil_cbh_2 > nearest_val:\n",
    "                        bin_edges = basta_bin_edges[nearest_id:nearest_id+2]\n",
    "                        midbin = (bin_edges[0]+bin_edges[1])/2.\n",
    "                        ceil_cbh_2_interp.append(midbin)\n",
    "\n",
    "                if np.isnan(nearest_ceil_cbh_3):\n",
    "                    ceil_cbh_3_interp.append(np.nan)\n",
    "                else:                      \n",
    "                    nearest_val,nearest_id = find_nearest(basta_bin_edges,nearest_ceil_cbh_3)\n",
    "                    if nearest_ceil_cbh_3 == nearest_val:\n",
    "                        bin_edges = basta_bin_edges[nearest_id-1:nearest_id+1]\n",
    "                        midbin = (bin_edges[0]+bin_edges[1])/2.\n",
    "                        ceil_cbh_3_interp.append(midbin)\n",
    "                    elif nearest_ceil_cbh_3 < nearest_val:\n",
    "                        bin_edges = basta_bin_edges[nearest_id-1:nearest_id+1]\n",
    "                        midbin = (bin_edges[0]+bin_edges[1])/2.\n",
    "                        ceil_cbh_3_interp.append(midbin)\n",
    "                    elif nearest_ceil_cbh_3 > nearest_val:\n",
    "                        bin_edges = basta_bin_edges[nearest_id:nearest_id+2]\n",
    "                        midbin = (bin_edges[0]+bin_edges[1])/2.\n",
    "                        ceil_cbh_3_interp.append(midbin)                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "            else:\n",
    "                #print('here')\n",
    "                #print(time_diff,basta_time_dt[ttt],ceil_time_dt[nearest_id])\n",
    "                ceil_cbh_1_interp.append(np.nan)\n",
    "                ceil_cbh_2_interp.append(np.nan)\n",
    "                ceil_cbh_3_interp.append(np.nan)\n",
    "                ceil_detection_status_interp.append(np.nan)\n",
    "                ceil_cbh_bin_relative_interp.append(np.nan)\n",
    "\n",
    "        ceil_cbh_1_interp = np.array(ceil_cbh_1_interp)\n",
    "        ceil_cbh_2_interp = np.array(ceil_cbh_2_interp)\n",
    "        ceil_cbh_3_interp = np.array(ceil_cbh_3_interp)\n",
    "        ceil_detection_status_interp = np.array(ceil_detection_status_interp)    \n",
    "        ceil_cbh_bin_relative_interp = np.array(ceil_cbh_bin_relative_interp)  \n",
    "        \n",
    "        \n",
    "        #============================================\n",
    "        # Plot to explore backscatter interpolation\n",
    "        #============================================\n",
    "\n",
    "        #if True:\n",
    "        if False:\n",
    "\n",
    "            fig = plt.figure(figsize=(24,14))\n",
    "            Fontsize=14\n",
    "            dfmt = mdates.DateFormatter('%H:%M')\n",
    "            ax_native = fig.add_subplot(211)\n",
    "            ax_interp_nn = fig.add_subplot(212)\n",
    "            #ax_interp_cubic1 = fig.add_subplot(223)\n",
    "            #ax_interp_linear = fig.add_subplot(224)\n",
    "            \n",
    "            basta_time_dt = np.array([toDatetime(basta_time_ts[dd]) for dd in range(len(basta_time_ts))])             \n",
    "            start_time = datetime.datetime(basta_time_dt[0].year,basta_time_dt[0].month,basta_time_dt[0].day,0,0)\n",
    "            #end_time = start_time + datetime.timedelta(days=1)           \n",
    "            end_time = start_time + datetime.timedelta(hours=24)           \n",
    "            \n",
    "            \n",
    "            #axlist = [ax_native,ax_interp_nn,ax_interp_cubic1,ax_interp_linear]\n",
    "            axlist = [ax_native,ax_interp_nn]\n",
    "            for ax in axlist:\n",
    "                ax.tick_params(labelsize=Fontsize)\n",
    "                ax.set_ylabel('Height [km]',fontsize=Fontsize)\n",
    "                ax.set_xlabel('UTC Time [HH:MM]',fontsize=Fontsize)\n",
    "                ax.xaxis.set_major_formatter(dfmt)\n",
    "                ax.grid(which='both',c='dimgrey',ls='dotted',lw=1)\n",
    "                ax.set_xlim(start_time,end_time)\n",
    "                ax.set_ylim(0,1)\n",
    "                \n",
    "            cmap = matplotlib.cm.get_cmap(\"jet\").copy()\n",
    "            cmap.set_under('navy')\n",
    "            cmap.set_bad('grey')\n",
    "\n",
    "            # Native\n",
    "            height_bins = ceil_range_bounds[:,0]\n",
    "            dumbin = np.array([height_bins[-1]+30])\n",
    "            height_bins = np.concatenate((height_bins,dumbin))\n",
    "\n",
    "            native_plot = ax_native.pcolormesh(ceil_time_dt,\\\n",
    "                                                             height_bins*1.e-3,\\\n",
    "                                                             ceil_backscatter[1:,:].T,\\\n",
    "                                                             cmap=cmap,\n",
    "                                                             vmin=-8,vmax=-3)\n",
    "            # Colorbar\n",
    "            dum_ticks = [-8,-7,-6,-5,-4,-3]\n",
    "            native_cbar = fig.colorbar(native_plot,ticks=dum_ticks,pad=0.01,ax=ax_native)\n",
    "            dumstr = '$log_{10}$($\\\\beta_{att}$)'\n",
    "            native_cbar.ax.set_ylabel(dumstr,fontsize=Fontsize)\n",
    "            native_cbar.ax.tick_params(labelsize=Fontsize)  \n",
    "            \n",
    "            ax_native.set_title('Native $\\\\beta_{att}$ \\n 30-m x 16-sec resolution',fontsize=Fontsize*1.5,color='dimgrey')\n",
    "            ax_native.scatter(ceil_time_dt,ceil_cbh_1*1.e-3,s=2,c='black')\n",
    "\n",
    "            \n",
    "            # Fill in obscured time periods with transparent red\n",
    "            id4 = np.where(ceil_detection_status == 4.)\n",
    "            detection_mask = np.zeros(np.shape(ceil_detection_status))\n",
    "            if np.size(id4) > 1.:\n",
    "                id4 = np.squeeze(id4)\n",
    "                detection_mask[id4] = 1\n",
    "                detection_Objects,num_detection_objects = ndimage.label(detection_mask)\n",
    "                for kk in range(num_detection_objects):\n",
    "                    dumid = np.where(detection_Objects == kk+1)[0]\n",
    "                    first_id = dumid[0]\n",
    "                    last_id = dumid[-1]\n",
    "                    ax_native.axvspan(ceil_time_dt[first_id],\\\n",
    "                                ceil_time_dt[last_id],color='red',alpha=0.5)               \n",
    "            \n",
    "            \n",
    "            \n",
    "            ceil_time_dt = np.array(ceil_time_dt)\n",
    "            ceil_time_dt_orig = ceil_time_dt.copy()\n",
    "            ceil_time_ts_orig = ceil_time_ts.copy()\n",
    "            \n",
    "            dumid = np.where( (ceil_time_ts >= basta_time_ts[0]) & (ceil_time_ts <= basta_time_ts[-1]))\n",
    "            if np.size(dumid) > 0.:\n",
    "                dumid = np.squeeze(dumid)\n",
    "                ceil_time_ts = ceil_time_ts[dumid]\n",
    "                ceil_time_dt = ceil_time_dt[dumid]\n",
    "                ceil_backscatter = ceil_backscatter[dumid,:]\n",
    "\n",
    "            # Interpolated in log10 space (nearest neighbor)            \n",
    "            x=ceil_time_ts = np.array([toTimestamp(ceil_time_dt[dd]) for dd in range(len(ceil_time_dt))])\n",
    "            y=ceil_range\n",
    "            #mask invalid values\n",
    "            z = ceil_backscatter.copy()\n",
    "            z = z.T\n",
    "            xx, yy = np.meshgrid(x, y)\n",
    "            basta_height_lim = basta_height[basta_height < np.max(ceil_range)]\n",
    "            newy = basta_height_lim\n",
    "            newx = basta_time_ts\n",
    "            \n",
    "            newX,newY = np.meshgrid(newx,newy)\n",
    "            ceil_backscatter_interp_nn = griddata((xx.ravel(), yy.ravel()), z.ravel(),(newX, newY),method='nearest',fill_value=np.nan)\n",
    "        \n",
    "            dumid = np.where( (basta_time_ts < ceil_time_ts_orig[0]) | (basta_time_ts > ceil_time_ts_orig[-1]) )\n",
    "            if np.size(dumid) > 0.:\n",
    "                dumid = np.squeeze(dumid)\n",
    "                ceil_cbh_1_interp[dumid] = np.nan\n",
    "                ceil_cbh_2_interp[dumid] = np.nan\n",
    "                ceil_cbh_3_interp[dumid] = np.nan\n",
    "                ceil_backscatter_interp_nn[:,dumid] = np.nan\n",
    "                ceil_detection_status_interp[dumid] = np.nan\n",
    "                ceil_cbh_bin_relative_interp[dumid] = np.nan   \n",
    "\n",
    "                 \n",
    "            # Need to deal with missing times in between the start and end time of the radar\n",
    "            # Let's loop through basta times and if the time is not within 12 seconds of a\n",
    "            # radar profile, we'll nan it out\n",
    "\n",
    "            for dum_tt in range(len(basta_time_dt)):\n",
    "                dum_diff = np.abs(basta_time_ts[dum_tt] - ceil_time_ts)\n",
    "                if np.min(dum_diff) > 12.:\n",
    "                    ceil_backscatter_interp_nn[:,dum_tt] = np.nan               \n",
    "                \n",
    "                \n",
    "                \n",
    "            basta_height_bins = np.arange(0,np.max(basta_height_lim),25)\n",
    "            dumbins = np.array([np.max(basta_height_lim)+12.5])\n",
    "            basta_height_bins = np.concatenate((basta_height_bins,dumbins))\n",
    "            interp_nn_plot = ax_interp_nn.pcolormesh(basta_time_dt,\\\n",
    "                                                             basta_height_bins*1.e-3,\\\n",
    "                                                             ceil_backscatter_interp_nn[:,1:],\\\n",
    "                                                             cmap=cmap,\n",
    "                                                             vmin=-8,vmax=-3)      \n",
    "            \n",
    "\n",
    "            # Colorbar\n",
    "            dum_ticks = [-8,-7,-6,-5,-4,-3]\n",
    "            interp_nn_cbar = fig.colorbar(interp_nn_plot,ticks=dum_ticks,pad=0.01,ax=ax_interp_nn)\n",
    "            dumstr = '$log_{10}$($\\\\beta_{att}$)'\n",
    "            interp_nn_cbar.ax.set_ylabel(dumstr,fontsize=Fontsize)\n",
    "            interp_nn_cbar.ax.tick_params(labelsize=Fontsize)  \n",
    "            \n",
    "            ax_interp_nn.set_title('Nearest Neighbor Interpolation $\\\\beta_{att}$ \\n 25-m x 12-sec resolution',fontsize=Fontsize*1.5,color='dimgrey')            \n",
    "            # Interpolated CBH\n",
    "            ax_interp_nn.scatter(basta_time_dt,ceil_cbh_1_interp*1.e-3,s=2,c='black')\n",
    "\n",
    "            \n",
    "            # Fill in obscured time periods with transparent red\n",
    "            id4 = np.where(ceil_detection_status_interp == 4.)\n",
    "            detection_mask = np.zeros(np.shape(ceil_detection_status_interp))\n",
    "            if np.size(id4) > 1.:\n",
    "                id4 = np.squeeze(id4)\n",
    "                detection_mask[id4] = 1\n",
    "                detection_Objects,num_detection_objects = ndimage.label(detection_mask)\n",
    "                for kk in range(num_detection_objects):\n",
    "                    dumid = np.where(detection_Objects == kk+1)[0]\n",
    "                    first_id = dumid[0]\n",
    "                    last_id = dumid[-1]\n",
    "                    ax_interp_nn.axvspan(basta_time_dt[first_id],\\\n",
    "                                basta_time_dt[last_id],color='red',alpha=0.5)               \n",
    "            \n",
    "            red_patch = mpatches.Patch(color='red',alpha=0.5,label='CEIL obscured')\n",
    "            lgnd = ax_interp_nn.legend(handles=[red_patch],\\\n",
    "                                fontsize=Fontsize*1.5,\\\n",
    "                                bbox_to_anchor=(1,1.2),\\\n",
    "                                ncol=1,loc='upper right',framealpha=0)\n",
    "\n",
    "            if False:\n",
    "                # Cubic Interpolation\n",
    "                x=ceil_time_ts = np.array([toTimestamp(ceil_time_dt[dd]) for dd in range(len(ceil_time_dt))])\n",
    "                y=ceil_range\n",
    "                #mask invalid values\n",
    "                z = ceil_backscatter.copy()\n",
    "                dumid = np.where(~np.isnan(z))\n",
    "                z[dumid] = 10.**z[dumid]\n",
    "                dumid = np.where(np.isnan(z))\n",
    "                z[dumid] = 0.\n",
    "                z = z.T\n",
    "                xx, yy = np.meshgrid(x, y)\n",
    "                basta_height_lim = basta_height[basta_height < np.max(ceil_range)]\n",
    "                newy = basta_height_lim\n",
    "                newx = basta_time_ts\n",
    "                newX,newY = np.meshgrid(newx,newy)\n",
    "                ceil_backscatter_interp_cubic1 = griddata((xx.ravel(), yy.ravel()), z.ravel(),(newX, newY),method='cubic',fill_value=np.nan)\n",
    "                dumid = np.where(~np.isnan(ceil_backscatter_interp_cubic1))\n",
    "                ceil_backscatter_interp_cubic1[dumid] = np.log10(ceil_backscatter_interp_cubic1[dumid])\n",
    "\n",
    "\n",
    "                basta_height_bins = np.arange(0,np.max(basta_height_lim),25)\n",
    "                dumbins = np.array([np.max(basta_height_lim)+12.5])\n",
    "                basta_height_bins = np.concatenate((basta_height_bins,dumbins))\n",
    "                interp_cubic1_plot = ax_interp_cubic1.pcolormesh(basta_time_dt,\\\n",
    "                                                                 basta_height_bins*1.e-3,\\\n",
    "                                                                 ceil_backscatter_interp_cubic1[:,1:],\\\n",
    "                                                                 cmap=cmap,\n",
    "                                                                 vmin=-8,vmax=-3)            \n",
    "\n",
    "                # Colorbar\n",
    "                dum_ticks = [-8,-7,-6,-5,-4,-3]\n",
    "                interp_cubic1_cbar = fig.colorbar(interp_cubic1_plot,ticks=dum_ticks,pad=0.01,ax=ax_interp_cubic1)\n",
    "                dumstr = '$log_{10}$($\\\\beta_{att}$)'\n",
    "                interp_cubic1_cbar.ax.set_ylabel(dumstr,fontsize=Fontsize)\n",
    "                interp_cubic1_cbar.ax.tick_params(labelsize=Fontsize)  \n",
    "\n",
    "                ax_interp_cubic1.set_title('Cubic Interpolation $\\\\beta_{att}$ \\n 25-m x 12-sec resolution',fontsize=Fontsize*1.5,color='dimgrey')            \n",
    "\n",
    "\n",
    "                # Linear Interpolation\n",
    "                x=ceil_time_ts = np.array([toTimestamp(ceil_time_dt[dd]) for dd in range(len(ceil_time_dt))])\n",
    "                y=ceil_range\n",
    "                #mask invalid values\n",
    "                z = ceil_backscatter.copy()\n",
    "                dumid = np.where(~np.isnan(z))\n",
    "                z[dumid] = 10.**z[dumid]\n",
    "                dumid = np.where(np.isnan(z))\n",
    "                z[dumid] = 0.\n",
    "                z = z.T\n",
    "                xx, yy = np.meshgrid(x, y)\n",
    "                basta_height_lim = basta_height[basta_height < np.max(ceil_range)]\n",
    "                newy = basta_height_lim\n",
    "                newx = basta_time_ts\n",
    "                newX,newY = np.meshgrid(newx,newy)\n",
    "                ceil_backscatter_interp_linear = griddata((xx.ravel(), yy.ravel()), z.ravel(),(newX, newY),method='linear',fill_value=np.nan)\n",
    "                dumid = np.where(~np.isnan(ceil_backscatter_interp_linear))\n",
    "                ceil_backscatter_interp_linear[dumid] = np.log10(ceil_backscatter_interp_linear[dumid])\n",
    "\n",
    "\n",
    "                basta_height_bins = np.arange(0,np.max(basta_height_lim),25)\n",
    "                dumbins = np.array([np.max(basta_height_lim)+12.5])\n",
    "                basta_height_bins = np.concatenate((basta_height_bins,dumbins))\n",
    "                interp_linear_plot = ax_interp_linear.pcolormesh(basta_time_dt,\\\n",
    "                                                                 basta_height_bins*1.e-3,\\\n",
    "                                                                 ceil_backscatter_interp_linear[:,1:],\\\n",
    "                                                                 cmap=cmap,\n",
    "                                                                 vmin=-8,vmax=-3)         \n",
    "                \n",
    "\n",
    "\n",
    "                # Colorbar\n",
    "                dum_ticks = [-8,-7,-6,-5,-4,-3]\n",
    "                interp_linear_cbar = fig.colorbar(interp_linear_plot,ticks=dum_ticks,pad=0.01,ax=ax_interp_linear)\n",
    "                dumstr = '$log_{10}$($\\\\beta_{att}$)'\n",
    "                interp_linear_cbar.ax.set_ylabel(dumstr,fontsize=Fontsize)\n",
    "                interp_linear_cbar.ax.tick_params(labelsize=Fontsize)  \n",
    "\n",
    "                ax_interp_linear.set_title('Linear Interpolation $\\\\beta_{att}$ \\n 25-m x 12-sec resolution',fontsize=Fontsize*1.5,color='dimgrey')                             \n",
    "            \n",
    "\n",
    "            #-------------------------------------\n",
    "            #-------------------------------------\n",
    "            # Fog ID\n",
    "            #-------------------------------------\n",
    "            #-------------------------------------\n",
    "            # For interpolated data, we want to come down from cloud base\n",
    "            # and determine whether or not there is a decade decrease in\n",
    "            # magnitude before reaching the lowest bin.\n",
    "            \n",
    "            fog_mask = np.zeros(np.shape(basta_time_dt))\n",
    "            min_diff_arr_out = np.zeros(np.shape(basta_time_dt))\n",
    "            for tt in range(len(basta_time_dt)):\n",
    "                if ceil_cbh_1_interp[tt] > 0.:\n",
    "                    height_id = np.where(basta_height == ceil_cbh_1_interp[tt])[0][0]\n",
    "                    cbh_beta = ceil_backscatter_interp_nn[height_id,tt]\n",
    "                    below_cbh_beta = ceil_backscatter_interp_nn[:height_id,tt]\n",
    "                    min_below_cbh_beta = np.nanmin(below_cbh_beta)\n",
    "                    dumdiff = cbh_beta - min_below_cbh_beta\n",
    "                    min_diff_arr_out[tt] = dumdiff\n",
    "                    if cbh_beta < -4.5:\n",
    "                        continue\n",
    "                    if np.isnan(dumdiff):\n",
    "                        continue\n",
    "                    elif (~np.isnan(dumdiff)) & (dumdiff >= 1.):\n",
    "                        continue\n",
    "                    elif (~np.isnan(dumdiff)) & (dumdiff < 1.):\n",
    "                        fog_mask[tt] = 1\n",
    "                else:\n",
    "                    min_diff_arr_out[tt] = np.nan\n",
    "                    \n",
    "            # Shade fog periods\n",
    "            # Fill in fog time periods with transparent blue\n",
    "            fog_id = np.where(fog_mask == 1.)\n",
    "            if np.size(fog_id) > 1.:\n",
    "                fog_Objects,num_fog_objects = ndimage.label(fog_mask)\n",
    "                for kk in range(num_fog_objects):\n",
    "                    dumid = np.where(fog_Objects == kk+1)[0]\n",
    "                    first_id = dumid[0]\n",
    "                    last_id = dumid[-1]\n",
    "                    ax_interp_nn.axvspan(basta_time_dt[first_id],\\\n",
    "                                basta_time_dt[last_id],color='navy',alpha=0.5)               \n",
    "                   \n",
    "            \n",
    "            blue_patch = mpatches.Patch(color='navy',alpha=0.5,label='Fog')\n",
    "            lgnd2 = ax_interp_nn.legend(handles=[blue_patch],\\\n",
    "                                fontsize=Fontsize*1.5,\\\n",
    "                                bbox_to_anchor=(0,1.2),\\\n",
    "                                ncol=1,loc='upper left',framealpha=0)                        \n",
    "            \n",
    "            \n",
    "            ax_interp_nn.add_artist(lgnd)\n",
    "            plt.subplots_adjust(hspace=0.3,wspace=0.1)\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        #================================================\n",
    "        # Interpolate backscatter to radar grid\n",
    "        #================================================\n",
    "        if interp_backscatter:\n",
    "            basta_time_dt = np.array([toDatetime(basta_time_ts[dd]) for dd in range(len(basta_time_ts))])             \n",
    "            start_time = datetime.datetime(basta_time_dt[0].year,basta_time_dt[0].month,basta_time_dt[0].day,0,0)\n",
    "            end_time = start_time + datetime.timedelta(hours=24)          \n",
    "\n",
    "            ceil_time_dt = np.array(ceil_time_dt)\n",
    "            ceil_time_dt_orig = ceil_time_dt.copy()\n",
    "            ceil_time_ts_orig = ceil_time_ts.copy()\n",
    "            ceil_backscatter_orig = ceil_backscatter.copy()\n",
    "\n",
    "            dumid = np.where( (ceil_time_ts >= basta_time_ts[0]) & (ceil_time_ts <= basta_time_ts[-1]))\n",
    "            if np.size(dumid) > 0.:\n",
    "                dumid = np.squeeze(dumid)\n",
    "                ceil_time_ts = ceil_time_ts[dumid]\n",
    "                ceil_time_dt = ceil_time_dt[dumid]\n",
    "                ceil_backscatter = ceil_backscatter[dumid,:]        \n",
    "\n",
    "            # Interpolated in log10 space (nearest neighbor)            \n",
    "            x=ceil_time_ts = np.array([toTimestamp(ceil_time_dt[dd]) for dd in range(len(ceil_time_dt))])\n",
    "            y=ceil_range\n",
    "            #mask invalid values\n",
    "            z = ceil_backscatter.copy()\n",
    "            z = z.T\n",
    "            xx, yy = np.meshgrid(x, y)\n",
    "            basta_height_lim = basta_height[basta_height < np.max(ceil_range)]\n",
    "            newy = basta_height_lim\n",
    "            newx = basta_time_ts\n",
    "\n",
    "            newX,newY = np.meshgrid(newx,newy)\n",
    "            ceil_backscatter_interp = griddata((xx.ravel(), yy.ravel()), z.ravel(),(newX, newY),method='nearest',fill_value=np.nan)\n",
    "            \n",
    "            dumid = np.where( (basta_time_ts < ceil_time_ts_orig[0]) | (basta_time_ts > ceil_time_ts_orig[-1]) )\n",
    "            if np.size(dumid) > 0.:\n",
    "                dumid = np.squeeze(dumid)\n",
    "                ceil_cbh_1_interp[dumid] = np.nan\n",
    "                ceil_cbh_2_interp[dumid] = np.nan\n",
    "                ceil_cbh_3_interp[dumid] = np.nan\n",
    "                ceil_backscatter_interp[:,dumid] = np.nan\n",
    "                ceil_detection_status_interp[dumid] = np.nan\n",
    "                ceil_cbh_bin_relative_interp[dumid] = np.nan\n",
    "            # Need to deal with missing times in between the start and end time of the radar\n",
    "            # Let's loop through basta times and if the time is not within 12 seconds of a\n",
    "            # radar profile, we'll nan it out\n",
    "            for dum_tt in range(len(basta_time_dt)):\n",
    "                dum_diff = np.abs(basta_time_ts[dum_tt] - ceil_time_ts)\n",
    "                if np.min(dum_diff) > 12.:\n",
    "                    ceil_backscatter_interp[:,dum_tt] = np.nan\n",
    "        else:\n",
    "                ceil_backscatter_interp = None\n",
    "                basta_height_lim = None            \n",
    "\n",
    "            \n",
    "        \n",
    "        arm_ceil_out_dict = {'cbh_1':ceil_cbh_1_interp,\\\n",
    "                    'cbh_2':ceil_cbh_2_interp,\\\n",
    "                    'cbh_3':ceil_cbh_3_interp,\\\n",
    "                    'detection_status':ceil_detection_status_interp,\\\n",
    "                    'backscatter':ceil_backscatter_interp,\\\n",
    "                    'native_cbh_1':ceil_cbh_1,\\\n",
    "                    'native_cbh_2':ceil_cbh_2,\\\n",
    "                    'native_cbh_3':ceil_cbh_3,\\\n",
    "                    'native_detection_status':ceil_detection_status,\\\n",
    "                    'native_backscatter':ceil_backscatter_orig,\\\n",
    "                    'native_time_dt':ceil_time_dt_orig,\\\n",
    "                    'native_time_ts':ceil_time_ts_orig,\\\n",
    "                    'native_range':ceil_range,\\\n",
    "                    'native_range_bounds':ceil_range_bounds,\\\n",
    "                    'interp_height':basta_height_lim,\\\n",
    "                    'cbh_bin_relative_interp':ceil_cbh_bin_relative_interp}\n",
    "     \n",
    "        return arm_ceil_present_flag,arm_ceil_out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200a9fab-1d86-43bc-839e-34b5ecf44cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f0cdc6f9-24e0-49dc-baa2-9ede38a3af20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_aad_ceil(date,aad_ceil_dates_dt,aad_ceil_files,avg_bool,basta_height,basta_time_ts,interp_backscatter=False):\n",
    "\n",
    "    tmpid = np.where(aad_ceil_dates_dt == date)\n",
    "    if np.size(tmpid) == 0.:\n",
    "        aad_ceil_present_flag = False\n",
    "        aad_ceil_out_dict = None\n",
    "        return aad_ceil_present_flag, aad_ceil_out_dict\n",
    "    elif np.size(tmpid) > 0.:        \n",
    "        aad_ceil_present_flag = True\n",
    "        tmpid = tmpid[0][0]\n",
    "        current_ceil_file = aad_ceil_files[tmpid]\n",
    "        ncfile = xarray.open_dataset(current_ceil_file,decode_times=False)    \n",
    "        ceil_dims = ncfile.dims\n",
    "        ceil_time_ts = np.array(ncfile['time']).copy()\n",
    "        ceil_cbh_1 = np.array(ncfile['cbh_1']).copy()\n",
    "        ceil_cbh_2 = np.array(ncfile['cbh_2']).copy()\n",
    "        ceil_cbh_3 = np.array(ncfile['cbh_3']).copy()\n",
    "        ceil_detection_status = np.array(ncfile['detection_status']).copy()\n",
    "        ceil_backscatter = np.array(ncfile['backscatter']).copy()\n",
    "        ceil_height = np.array(ncfile['height']).copy()\n",
    "        ceil_num_times = ceil_dims['time_dim']\n",
    "        ceil_time_dt = np.array([toDatetime(ceil_time_ts[dd]) for dd in range(ceil_num_times)]  )  \n",
    "        ncfile.close()\n",
    "\n",
    "        #------------------------------------------\n",
    "        # Interpolate ceilometer to radar time grid\n",
    "        # using nearest neighbor interpolation. \n",
    "        # This method requires that the nearest\n",
    "        # neighbor be within 15 seconds of the\n",
    "        # radar time grid element.\n",
    "        #------------------------------------------\n",
    "\n",
    "        basta_bin_edges = np.arange(0,np.max(basta_height)+12.5+25.,25.)\n",
    "        basta_time_dt = np.array([toDatetime(basta_time_ts[dd]) for dd in range(len(basta_time_ts))])\n",
    "\n",
    "        ceil_cbh_1_interp = []\n",
    "        ceil_cbh_2_interp = []\n",
    "        ceil_cbh_3_interp = []\n",
    "        ceil_detection_status_interp = []\n",
    "        ceil_cbh_bin_relative_interp = []\n",
    "        \n",
    "        for ttt in range(len(basta_time_ts)):\n",
    "            # if here, then good radar data exists\n",
    "            # Now find the nearest in time ceilometer time step to the radar time step\n",
    "            # If the ceilometer is more than 15 seconds away from the the radar time step,\n",
    "            # then we will flag it as missing data (NaN)\n",
    "            nearest_val,nearest_id = find_nearest(ceil_time_ts,basta_time_ts[ttt])\n",
    "            time_diff = np.abs(nearest_val - basta_time_ts[ttt])\n",
    "            target_time_diff = 16\n",
    "            if time_diff <= target_time_diff:\n",
    "                nearest_ceil_cbh_1 = ceil_cbh_1[nearest_id]\n",
    "                nearest_ceil_cbh_2 = ceil_cbh_2[nearest_id]\n",
    "                nearest_ceil_cbh_3 = ceil_cbh_3[nearest_id]\n",
    "                nearest_ceil_detection_status = ceil_detection_status[nearest_id]\n",
    "                ceil_detection_status_interp.append(nearest_ceil_detection_status)\n",
    "\n",
    "                if np.isnan(nearest_ceil_detection_status):\n",
    "                    #ceil_detection_status_interp.append(np.nan)\n",
    "                    ceil_cbh_1_interp.append(np.nan)\n",
    "                    ceil_cbh_2_interp.append(np.nan)\n",
    "                    ceil_cbh_3_interp.append(np.nan)\n",
    "                    ceil_cbh_bin_relative_interp.append(np.nan)\n",
    "                    continue\n",
    "                    \n",
    "                elif (nearest_ceil_detection_status == 5.) or (nearest_ceil_detection_status == 0.):\n",
    "                    ceil_cbh_1_interp.append(-999.)\n",
    "                    ceil_cbh_2_interp.append(-999.)\n",
    "                    ceil_cbh_3_interp.append(-999.)\n",
    "                    ceil_cbh_bin_relative_interp.append(-999.)\n",
    "                    continue\n",
    "                    \n",
    "                elif (nearest_ceil_detection_status == 4.):\n",
    "                    ceil_cbh_1_interp.append(np.nan)\n",
    "                    ceil_cbh_2_interp.append(np.nan)\n",
    "                    ceil_cbh_3_interp.append(np.nan)\n",
    "                    ceil_cbh_bin_relative_interp.append(np.nan)\n",
    "                    continue                    \n",
    "                    \n",
    "                elif (nearest_ceil_detection_status == 1.) or (nearest_ceil_detection_status == 2.) or (nearest_ceil_detection_status == 3.):\n",
    "                    pass\n",
    "                else:\n",
    "                    raise RuntimeError('Something went wrong')\n",
    "\n",
    "                #if np.isnan(nearest_ceil_cbh_1):\n",
    "                #    ceil_cbh_1_interp.append(np.nan)\n",
    "                #    ceil_cbh_2_interp.append(np.nan)\n",
    "                #    ceil_cbh_3_interp.append(np.nan)\n",
    "                #    ceil_cbh_bin_relative_interp.append(np.nan)\n",
    "                #    continue \n",
    "                    \n",
    "                nearest_val,nearest_id = find_nearest(basta_bin_edges,nearest_ceil_cbh_1)\n",
    "                if nearest_ceil_cbh_1 > 12000.:\n",
    "                    ceil_cbh_1_interp.append(-999.)\n",
    "                    ceil_cbh_2_interp.append(-999.)\n",
    "                    ceil_cbh_3_interp.append(-999.)\n",
    "                    ceil_cbh_bin_relative_interp.append(-999.)\n",
    "                    ceil_detection_status_interp[ttt] = 0.\n",
    "                else:\n",
    "                    if nearest_ceil_cbh_1 == nearest_val:\n",
    "                        bin_edges = basta_bin_edges[nearest_id-1:nearest_id+1]\n",
    "                        midbin = (bin_edges[0]+bin_edges[1])/2.\n",
    "                        ceil_cbh_1_interp.append(midbin)\n",
    "                        ceil_cbh_bin_relative_interp.append(1.)\n",
    "                    elif nearest_ceil_cbh_1 < nearest_val:\n",
    "                        bin_edges = basta_bin_edges[nearest_id-1:nearest_id+1]\n",
    "                        midbin = (bin_edges[0]+bin_edges[1])/2.\n",
    "                        ceil_cbh_1_interp.append(midbin)\n",
    "                        ceil_cbh_bin_relative_interp.append(0.)\n",
    "                    elif nearest_ceil_cbh_1 > nearest_val:\n",
    "                        bin_edges = basta_bin_edges[nearest_id:nearest_id+2]\n",
    "                        midbin = (bin_edges[0]+bin_edges[1])/2.\n",
    "                        ceil_cbh_1_interp.append(midbin)\n",
    "                        ceil_cbh_bin_relative_interp.append(2.)\n",
    "\n",
    "                    if np.isnan(nearest_ceil_cbh_2):\n",
    "                        ceil_cbh_2_interp.append(np.nan)\n",
    "                    else:    \n",
    "                        nearest_val,nearest_id = find_nearest(basta_bin_edges,nearest_ceil_cbh_2)\n",
    "                        if nearest_ceil_cbh_2 == nearest_val:\n",
    "                            bin_edges = basta_bin_edges[nearest_id-1:nearest_id+1]\n",
    "                            midbin = (bin_edges[0]+bin_edges[1])/2.\n",
    "                            ceil_cbh_2_interp.append(midbin)\n",
    "                        elif nearest_ceil_cbh_2 < nearest_val:\n",
    "                            bin_edges = basta_bin_edges[nearest_id-1:nearest_id+1]\n",
    "                            midbin = (bin_edges[0]+bin_edges[1])/2.\n",
    "                            ceil_cbh_2_interp.append(midbin)\n",
    "                        elif nearest_ceil_cbh_2 > nearest_val:\n",
    "                            bin_edges = basta_bin_edges[nearest_id:nearest_id+2]\n",
    "                            midbin = (bin_edges[0]+bin_edges[1])/2.\n",
    "                            ceil_cbh_2_interp.append(midbin)\n",
    "\n",
    "                    if np.isnan(nearest_ceil_cbh_3):\n",
    "                        ceil_cbh_3_interp.append(np.nan)\n",
    "                    else:                      \n",
    "                        nearest_val,nearest_id = find_nearest(basta_bin_edges,nearest_ceil_cbh_3)\n",
    "                        if nearest_ceil_cbh_3 == nearest_val:\n",
    "                            bin_edges = basta_bin_edges[nearest_id-1:nearest_id+1]\n",
    "                            midbin = (bin_edges[0]+bin_edges[1])/2.\n",
    "                            ceil_cbh_3_interp.append(midbin)\n",
    "                        elif nearest_ceil_cbh_3 < nearest_val:\n",
    "                            bin_edges = basta_bin_edges[nearest_id-1:nearest_id+1]\n",
    "                            midbin = (bin_edges[0]+bin_edges[1])/2.\n",
    "                            ceil_cbh_3_interp.append(midbin)\n",
    "                        elif nearest_ceil_cbh_3 > nearest_val:\n",
    "                            bin_edges = basta_bin_edges[nearest_id:nearest_id+2]\n",
    "                            midbin = (bin_edges[0]+bin_edges[1])/2.\n",
    "                            ceil_cbh_3_interp.append(midbin)                    \n",
    "\n",
    "\n",
    "                if np.isnan(ceil_cbh_1_interp[ttt]):\n",
    "                    print(aaaa)\n",
    "            else:\n",
    "                #print('here')\n",
    "                #print(time_diff,basta_time_dt[ttt],ceil_time_dt[nearest_id])\n",
    "                ceil_cbh_1_interp.append(np.nan)\n",
    "                ceil_cbh_2_interp.append(np.nan)\n",
    "                ceil_cbh_3_interp.append(np.nan)\n",
    "                ceil_detection_status_interp.append(np.nan)\n",
    "                ceil_cbh_bin_relative_interp.append(np.nan)\n",
    "\n",
    "        ceil_cbh_1_interp = np.array(ceil_cbh_1_interp)\n",
    "        ceil_cbh_2_interp = np.array(ceil_cbh_2_interp)\n",
    "        ceil_cbh_3_interp = np.array(ceil_cbh_3_interp)\n",
    "        ceil_detection_status_interp = np.array(ceil_detection_status_interp)    \n",
    "        ceil_cbh_bin_relative_interp = np.array(ceil_cbh_bin_relative_interp) \n",
    "            \n",
    "        #dumid = np.where(ceil_height <= np.max(basta_height))\n",
    "        #dumid = np.squeeze(dumid)\n",
    "        #ceil_backscatter = ceil_backscatter[:,dumid]\n",
    "        ceil_backscatter[ceil_backscatter == 0.] = np.nan\n",
    "        \n",
    "    \n",
    "\n",
    "        \n",
    "                \n",
    "        #============================================\n",
    "        # Plot to explore backscatter interpolation\n",
    "        #============================================\n",
    "        #if True: \n",
    "        if False:\n",
    "\n",
    "            fig = plt.figure(figsize=(24,14))\n",
    "            Fontsize=14\n",
    "            dfmt = mdates.DateFormatter('%H:%M')\n",
    "            ax_native = fig.add_subplot(211)\n",
    "            ax_interp_nn = fig.add_subplot(212)\n",
    "            \n",
    "            basta_time_dt = np.array([toDatetime(basta_time_ts[dd]) for dd in range(len(basta_time_ts))])             \n",
    "            start_time = datetime.datetime(basta_time_dt[0].year,basta_time_dt[0].month,basta_time_dt[0].day,0,0)\n",
    "            #end_time = start_time + datetime.timedelta(days=1)           \n",
    "            end_time = start_time + datetime.timedelta(hours=24)           \n",
    "            \n",
    "            axlist = [ax_native,ax_interp_nn]\n",
    "            for ax in axlist:\n",
    "                ax.tick_params(labelsize=Fontsize)\n",
    "                ax.set_ylabel('Height [km]',fontsize=Fontsize)\n",
    "                ax.set_xlabel('UTC Time [HH:MM]',fontsize=Fontsize)\n",
    "                ax.xaxis.set_major_formatter(dfmt)\n",
    "                ax.grid(which='both',c='dimgrey',ls='dotted',lw=1)\n",
    "                ax.set_xlim(start_time,end_time)\n",
    "                ax.set_ylim(0,1)\n",
    "                \n",
    "            cmap = matplotlib.cm.get_cmap(\"jet\").copy()\n",
    "            cmap.set_under('navy')\n",
    "            cmap.set_bad('grey')\n",
    "\n",
    "            # Native\n",
    "            height_bins = np.arange(0,np.max(ceil_height),10)\n",
    "            dumbin = np.array([height_bins[-1]+10])\n",
    "            height_bins = np.concatenate((height_bins,dumbin))\n",
    "\n",
    "            native_plot = ax_native.pcolormesh(ceil_time_dt,\\\n",
    "                                                             height_bins*1.e-3,\\\n",
    "                                                             ceil_backscatter[1:,:].T,\\\n",
    "                                                             cmap=cmap,\n",
    "                                                             vmin=-8,vmax=-3)\n",
    "            # Colorbar\n",
    "            dum_ticks = [-8,-7,-6,-5,-4,-3]\n",
    "            native_cbar = fig.colorbar(native_plot,ticks=dum_ticks,pad=0.01,ax=ax_native)\n",
    "            dumstr = '$log_{10}$($\\\\beta_{att}$)'\n",
    "            native_cbar.ax.set_ylabel(dumstr,fontsize=Fontsize)\n",
    "            native_cbar.ax.tick_params(labelsize=Fontsize)  \n",
    "            \n",
    "            ax_native.set_title('Native $\\\\beta_{att}$ \\n 10-m x 6-sec resolution',fontsize=Fontsize*1.5,color='dimgrey')\n",
    "            ax_native.scatter(ceil_time_dt,ceil_cbh_1*1.e-3,s=2,c='black')\n",
    "            \n",
    "            # Fill in obscured time periods with transparent red\n",
    "            id4 = np.where(ceil_detection_status == 4.)\n",
    "            detection_mask = np.zeros(np.shape(ceil_detection_status))\n",
    "            if np.size(id4) > 1.:\n",
    "                id4 = np.squeeze(id4)\n",
    "                detection_mask[id4] = 1\n",
    "                detection_Objects,num_detection_objects = ndimage.label(detection_mask)\n",
    "                for kk in range(num_detection_objects):\n",
    "                    dumid = np.where(detection_Objects == kk+1)[0]\n",
    "                    first_id = dumid[0]\n",
    "                    last_id = dumid[-1]\n",
    "                    ax_native.axvspan(ceil_time_dt[first_id],\\\n",
    "                                ceil_time_dt[last_id],color='red',alpha=0.5)               \n",
    "            \n",
    "            \n",
    "            \n",
    "            #ceil_time_dt = np.array(ceil_time_dt)\n",
    "            ceil_time_dt_orig = ceil_time_dt.copy()\n",
    "            ceil_time_ts_orig = ceil_time_ts.copy()\n",
    "            \n",
    "            dumid = np.where( (ceil_time_ts >= basta_time_ts[0]) & (ceil_time_ts <= basta_time_ts[-1]))\n",
    "            if np.size(dumid) > 0.:\n",
    "                dumid = np.squeeze(dumid)\n",
    "                ceil_time_ts = ceil_time_ts[dumid]\n",
    "                ceil_time_dt = ceil_time_dt[dumid]\n",
    "                ceil_backscatter = ceil_backscatter[dumid,:]\n",
    "                \n",
    "                \n",
    "            # Interpolated in log10 space (nearest neighbor)\n",
    "            x=ceil_time_ts = np.array([toTimestamp(ceil_time_dt[dd]) for dd in range(len(ceil_time_dt))])\n",
    "            y=ceil_height\n",
    "            #mask invalid values\n",
    "            z = ceil_backscatter.copy()\n",
    "            z = z.T\n",
    "            xx, yy = np.meshgrid(x, y)\n",
    "            #basta_height_lim = basta_height[basta_height < np.max(ceil_range)]\n",
    "            #newy = basta_height_lim\n",
    "            newy = basta_height\n",
    "            newx = basta_time_ts\n",
    "            newX,newY = np.meshgrid(newx,newy)\n",
    "            ceil_backscatter_interp_nn = griddata((xx.ravel(), yy.ravel()), z.ravel(),(newX, newY),method='nearest',fill_value=np.nan)\n",
    "            \n",
    "            dumid = np.where( (basta_time_ts < ceil_time_ts_orig[0]) | (basta_time_ts > ceil_time_ts_orig[-1]) )\n",
    "            if np.size(dumid) > 0.:\n",
    "                dumid = np.squeeze(dumid)\n",
    "                ceil_cbh_1_interp[dumid] = np.nan\n",
    "                ceil_cbh_2_interp[dumid] = np.nan\n",
    "                ceil_cbh_3_interp[dumid] = np.nan\n",
    "                ceil_backscatter_interp_nn[:,dumid] = np.nan\n",
    "                ceil_detection_status_interp[dumid] = np.nan\n",
    "                ceil_cbh_bin_relative_interp[dumid] = np.nan\n",
    "                \n",
    "            # Need to deal with missing times in between the start and end time of the radar\n",
    "            # Let's loop through basta times and if the time is not within 12 seconds of a\n",
    "            # radar profile, we'll nan it out\n",
    "\n",
    "            for dum_tt in range(len(basta_time_dt)):\n",
    "                dum_diff = np.abs(basta_time_ts[dum_tt] - ceil_time_ts)\n",
    "                if np.min(dum_diff) > 12.:\n",
    "                    ceil_backscatter_interp_nn[:,dum_tt] = np.nan\n",
    "            \n",
    "                \n",
    "            basta_height_bins = np.arange(0,np.max(basta_height),25)\n",
    "            dumbins = np.array([np.max(basta_height)+12.5])\n",
    "            basta_height_bins = np.concatenate((basta_height_bins,dumbins))\n",
    "            interp_nn_plot = ax_interp_nn.pcolormesh(basta_time_dt,\\\n",
    "                                                             basta_height_bins*1.e-3,\\\n",
    "                                                             ceil_backscatter_interp_nn[:,1:],\\\n",
    "                                                             cmap=cmap,\n",
    "                                                             vmin=-8,vmax=-3)            \n",
    "            \n",
    "            # Colorbar\n",
    "            dum_ticks = [-8,-7,-6,-5,-4,-3]\n",
    "            interp_nn_cbar = fig.colorbar(interp_nn_plot,ticks=dum_ticks,pad=0.01,ax=ax_interp_nn)\n",
    "            dumstr = '$log_{10}$($\\\\beta_{att}$)'\n",
    "            interp_nn_cbar.ax.set_ylabel(dumstr,fontsize=Fontsize)\n",
    "            interp_nn_cbar.ax.tick_params(labelsize=Fontsize)  \n",
    "            \n",
    "            ax_interp_nn.set_title('Nearest Neighbor Interpolation $\\\\beta_{att}$ \\n 25-m x 12-sec resolution',fontsize=Fontsize*1.5,color='dimgrey')            \n",
    "            # Interpolated CBH\n",
    "            ax_interp_nn.scatter(basta_time_dt,ceil_cbh_1_interp*1.e-3,s=2,c='black')\n",
    "\n",
    "            \n",
    "            # Fill in obscured time periods with transparent red\n",
    "            id4 = np.where(ceil_detection_status_interp == 4.)\n",
    "            detection_mask = np.zeros(np.shape(ceil_detection_status_interp))\n",
    "            if np.size(id4) > 1.:\n",
    "                id4 = np.squeeze(id4)\n",
    "                detection_mask[id4] = 1\n",
    "                detection_Objects,num_detection_objects = ndimage.label(detection_mask)\n",
    "                for kk in range(num_detection_objects):\n",
    "                    dumid = np.where(detection_Objects == kk+1)[0]\n",
    "                    first_id = dumid[0]\n",
    "                    last_id = dumid[-1]\n",
    "                    ax_interp_nn.axvspan(basta_time_dt[first_id],\\\n",
    "                                basta_time_dt[last_id],color='red',alpha=0.5)               \n",
    "            \n",
    "            red_patch = mpatches.Patch(color='red',alpha=0.5,label='CEIL obscured')\n",
    "            lgnd = ax_interp_nn.legend(handles=[red_patch],\\\n",
    "                                fontsize=Fontsize*1.5,\\\n",
    "                                bbox_to_anchor=(1,1.2),\\\n",
    "                                ncol=1,loc='upper right',framealpha=0)\n",
    "            \n",
    "\n",
    "            #-------------------------------------\n",
    "            #-------------------------------------\n",
    "            # Fog ID\n",
    "            #-------------------------------------\n",
    "            #-------------------------------------\n",
    "            # For interpolated data, we want to come down from cloud base\n",
    "            # and determine whether or not there is a decade decrease in\n",
    "            # magnitude before reaching the lowest bin.\n",
    "            \n",
    "            fog_mask = np.zeros(np.shape(basta_time_dt))\n",
    "            min_diff_arr_out = np.zeros(np.shape(basta_time_dt))\n",
    "            for tt in range(len(basta_time_dt)):\n",
    "                if ceil_cbh_1_interp[tt] > 0.:\n",
    "                    height_id = np.where(basta_height == ceil_cbh_1_interp[tt])#[0][0]\n",
    "                    #height_id = np.squeeze(height_id)\n",
    "                    #height_id = height_id[0]\n",
    "                    #print(np.shape(height_id))\n",
    "                    continue\n",
    "                    cbh_beta = ceil_backscatter_interp_nn[height_id,tt]\n",
    "                    below_cbh_beta = ceil_backscatter_interp_nn[:height_id,tt]\n",
    "                    min_below_cbh_beta = np.nanmin(below_cbh_beta)\n",
    "                    dumdiff = cbh_beta - min_below_cbh_beta\n",
    "                    min_diff_arr_out[tt] = dumdiff\n",
    "                    if cbh_beta < -4.5:\n",
    "                        continue\n",
    "                    if np.isnan(dumdiff):\n",
    "                        continue\n",
    "                    elif (~np.isnan(dumdiff)) & (dumdiff >= 1.):\n",
    "                        continue\n",
    "                    elif (~np.isnan(dumdiff)) & (dumdiff < 1.):\n",
    "                        fog_mask[tt] = 1\n",
    "                else:\n",
    "                    min_diff_arr_out[tt] = np.nan\n",
    "            #print(aaaa)\n",
    "            # Shade fog periods\n",
    "            # Fill in fog time periods with transparent blue\n",
    "            fog_id = np.where(fog_mask == 1.)\n",
    "            if np.size(fog_id) > 1.:\n",
    "                fog_Objects,num_fog_objects = ndimage.label(fog_mask)\n",
    "                for kk in range(num_fog_objects):\n",
    "                    dumid = np.where(fog_Objects == kk+1)[0]\n",
    "                    first_id = dumid[0]\n",
    "                    last_id = dumid[-1]\n",
    "                    ax_interp_nn.axvspan(basta_time_dt[first_id],\\\n",
    "                                basta_time_dt[last_id],color='navy',alpha=0.5)               \n",
    "                   \n",
    "            \n",
    "            blue_patch = mpatches.Patch(color='navy',alpha=0.5,label='Fog')\n",
    "            lgnd2 = ax_interp_nn.legend(handles=[blue_patch],\\\n",
    "                                fontsize=Fontsize*1.5,\\\n",
    "                                bbox_to_anchor=(0,1.2),\\\n",
    "                                ncol=1,loc='upper left',framealpha=0)                        \n",
    "            \n",
    "            \n",
    "            ax_interp_nn.add_artist(lgnd)\n",
    "            plt.subplots_adjust(hspace=0.3,wspace=0.1)\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "\n",
    "          \n",
    "            \n",
    "        #================================================\n",
    "        # Interpolate backscatter to radar grid\n",
    "        #================================================            \n",
    "        if interp_backscatter:\n",
    "            basta_time_dt = np.array([toDatetime(basta_time_ts[dd]) for dd in range(len(basta_time_ts))])             \n",
    "            start_time = datetime.datetime(basta_time_dt[0].year,basta_time_dt[0].month,basta_time_dt[0].day,0,0)\n",
    "            end_time = start_time + datetime.timedelta(hours=24)          \n",
    "\n",
    "            ceil_time_dt = np.array(ceil_time_dt)\n",
    "            ceil_time_dt_orig = ceil_time_dt.copy()\n",
    "            ceil_time_ts_orig = ceil_time_ts.copy()\n",
    "            ceil_backscatter_orig = ceil_backscatter.copy()\n",
    "\n",
    "            dumid = np.where( (ceil_time_ts >= basta_time_ts[0]) & (ceil_time_ts <= basta_time_ts[-1]))\n",
    "            if np.size(dumid) > 0.:\n",
    "                dumid = np.squeeze(dumid)\n",
    "                ceil_time_ts = ceil_time_ts[dumid]\n",
    "                ceil_time_dt = ceil_time_dt[dumid]\n",
    "                ceil_backscatter = ceil_backscatter[dumid,:]        \n",
    "\n",
    "            # Interpolated in log10 space (nearest neighbor)\n",
    "            x=ceil_time_ts = np.array([toTimestamp(ceil_time_dt[dd]) for dd in range(len(ceil_time_dt))])\n",
    "            y=ceil_height\n",
    "            #mask invalid values\n",
    "            z = ceil_backscatter.copy()\n",
    "            z = z.T\n",
    "            xx, yy = np.meshgrid(x, y)\n",
    "            #basta_height_lim = basta_height[basta_height < np.max(ceil_range)]\n",
    "            #newy = basta_height_lim\n",
    "            newy = basta_height\n",
    "            newx = basta_time_ts\n",
    "            newX,newY = np.meshgrid(newx,newy)\n",
    "            ceil_backscatter_interp = griddata((xx.ravel(), yy.ravel()), z.ravel(),(newX, newY),method='nearest',fill_value=np.nan)\n",
    "\n",
    "            dumid = np.where( (basta_time_ts < ceil_time_ts_orig[0]) | (basta_time_ts > ceil_time_ts_orig[-1]) )\n",
    "            if np.size(dumid) > 0.:\n",
    "                dumid = np.squeeze(dumid)\n",
    "                ceil_cbh_1_interp[dumid] = np.nan\n",
    "                ceil_cbh_2_interp[dumid] = np.nan\n",
    "                ceil_cbh_3_interp[dumid] = np.nan\n",
    "                ceil_backscatter_interp[:,dumid] = np.nan\n",
    "                ceil_detection_status_interp[dumid] = np.nan\n",
    "                ceil_cbh_bin_relative_interp[dumid] = np.nan\n",
    "\n",
    "            # Need to deal with missing times in between the start and end time of the radar\n",
    "            # Let's loop through basta times and if the time is not within 16 seconds of a\n",
    "            # radar profile, we'll nan it out\n",
    "            for dum_tt in range(len(basta_time_dt)):\n",
    "                dum_diff = np.abs(basta_time_ts[dum_tt] - ceil_time_ts)\n",
    "                if np.min(dum_diff) > 16.:\n",
    "                    ceil_backscatter_interp[:,dum_tt] = np.nan\n",
    "        else:\n",
    "            ceil_backscatter_interp = None\n",
    "            basta_height_lim = None            \n",
    "                  \n",
    "        \n",
    "        aad_ceil_out_dict = {'cbh_1':ceil_cbh_1_interp,\\\n",
    "                    'cbh_2':ceil_cbh_2_interp,\\\n",
    "                    'cbh_3':ceil_cbh_3_interp,\\\n",
    "                    'detection_status':ceil_detection_status_interp,\\\n",
    "                    'backscatter':ceil_backscatter_interp,\\\n",
    "                    'native_cbh_1':ceil_cbh_1,\\\n",
    "                    'native_cbh_2':ceil_cbh_2,\\\n",
    "                    'native_cbh_3':ceil_cbh_3,\\\n",
    "                    'native_detection_status':ceil_detection_status,\\\n",
    "                    'native_backscatter':ceil_backscatter_orig,\\\n",
    "                    'native_time_dt':ceil_time_dt_orig,\\\n",
    "                    'native_time_ts':ceil_time_ts_orig,\\\n",
    "                    'native_range':ceil_height,\\\n",
    "                    'interp_height':basta_height,\\\n",
    "                    'cbh_bin_relative_interp':ceil_cbh_bin_relative_interp,\\\n",
    "                   }\n",
    "     \n",
    "        return aad_ceil_present_flag,aad_ceil_out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c5ca76ea-03df-438a-905e-c44adae77f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_ceil(aad_ceil_dict,arm_ceil_dict,basta_time_dt):\n",
    "\n",
    "    arm_cbh_1 = arm_ceil_dict['cbh_1']\n",
    "    arm_cbh_2 = arm_ceil_dict['cbh_2']\n",
    "    arm_cbh_3 = arm_ceil_dict['cbh_3']\n",
    "    arm_detection_status = arm_ceil_dict['detection_status']\n",
    "    arm_cbh_bin_relative_interp = arm_ceil_dict['cbh_bin_relative_interp']\n",
    "\n",
    "    aad_cbh_1 = aad_ceil_dict['cbh_1']\n",
    "    aad_cbh_2 = aad_ceil_dict['cbh_2']\n",
    "    aad_cbh_3 = aad_ceil_dict['cbh_3']\n",
    "    aad_detection_status = aad_ceil_dict['detection_status']\n",
    "    aad_cbh_bin_relative_interp = aad_ceil_dict['cbh_bin_relative_interp']    \n",
    "    \n",
    "    #merge_cbh_1 = np.zeros(np.shape(basta_time_dt))\n",
    "    #merge_cbh_2 = np.zeros(np.shape(basta_time_dt))\n",
    "    #merge_cbh_3 = np.zeros(np.shape(basta_time_dt))\n",
    "    #merge_detection_status = np.zeros(np.shape(basta_time_dt))\n",
    "    #merge_cbh_bin_relative_interp = np.zeros(np.shape(basta_time_dt))\n",
    "    #merge_source_ceil = np.zeros(np.shape(basta_time_dt))\n",
    "    \n",
    "    merge_cbh_1 = arm_cbh_1.copy()\n",
    "    merge_cbh_2 = arm_cbh_2.copy()\n",
    "    merge_cbh_3 = arm_cbh_3.copy()\n",
    "    merge_detection_status = arm_detection_status.copy()\n",
    "    merge_cbh_bin_relative_interp = arm_cbh_bin_relative_interp.copy()\n",
    "    merge_source_ceil = np.zeros(np.shape(basta_time_dt))\n",
    "    merge_source_ceil[:] = 1\n",
    "    \n",
    "    # Anything with ceil_detection_status == NaN means that the ceilometer\n",
    "    # did not have a reading within 16 seconds or that the ceilometer value was\n",
    "    # generally bad. \n",
    "    #\n",
    "    # If one ceilometer exists at this time step but the other doesn't, then the merge\n",
    "    # ceilometer will use the ceilometer that DOES exist\n",
    "    dumid_nan = np.where(np.isnan(arm_detection_status) & np.isnan(aad_detection_status))\n",
    "    dumid_aad = np.where( np.isnan(arm_detection_status) & ~np.isnan(aad_detection_status) )\n",
    "    dumid_arm = np.where( ~np.isnan(arm_detection_status) & np.isnan(aad_detection_status) )\n",
    "    dumid_id4 = np.where( (arm_detection_status == 4.) & (aad_detection_status != 4.) & ~np.isnan(aad_detection_status) )\n",
    "    #print('nan:',np.size(dumid_nan))\n",
    "    #print('aad:',np.size(dumid_aad))\n",
    "    #print('arm:',np.size(dumid_arm))\n",
    "    #print('id4:',np.size(dumid_id4))\n",
    "    \n",
    "    # ARM Ceilometer is obscured but AAD Ceilometer is not\n",
    "    if np.size(dumid_id4) > 0.:\n",
    "        dumid_id4 = np.squeeze(dumid_id4)\n",
    "        merge_cbh_bin_relative_interp[dumid_id4] = aad_cbh_bin_relative_interp[dumid_id4]\n",
    "        merge_cbh_1[dumid_id4] = aad_cbh_1[dumid_id4]\n",
    "        merge_cbh_2[dumid_id4] = aad_cbh_2[dumid_id4]\n",
    "        merge_cbh_3[dumid_id4] = aad_cbh_3[dumid_id4]\n",
    "        merge_detection_status[dumid_id4] = aad_detection_status[dumid_id4]\n",
    "        merge_source_ceil[dumid_id4] = 2\n",
    "    \n",
    "    # No ceilometer at all\n",
    "    if np.size(dumid_nan) > 0.:\n",
    "        dumid_nan = np.squeeze(dumid_nan)\n",
    "        merge_cbh_bin_relative_interp[dumid_nan] = np.nan\n",
    "        merge_cbh_1[dumid_nan] = np.nan\n",
    "        merge_cbh_2[dumid_nan] = np.nan\n",
    "        merge_cbh_3[dumid_nan] = np.nan\n",
    "        merge_detection_status[dumid_nan] = np.nan\n",
    "        merge_source_ceil[dumid_nan] = np.nan\n",
    "        \n",
    "    #if np.size(dumid_999) > 0.:\n",
    "    #    dumid_999 = np.squeeze(dumid_999)\n",
    "    #    merge_cbh_bin_relative_interp[dumid_999] = np.nan\n",
    "    #    merge_detection_status[dumid_999] = np.nan\n",
    "    #    merge_cbh_1[dumid_999] = np.nan\n",
    "    #    merge_cbh_2[dumid_999] = np.nan\n",
    "    #    merge_cbh_3[dumid_999] = np.nan\n",
    "    #    merge_source_ceil[dumid_999] = np.nan\n",
    "    \n",
    "    #if False:\n",
    "    if True:\n",
    "        if np.size(dumid_aad) > 0.:\n",
    "            dumid_aad = np.squeeze(dumid_aad)\n",
    "            merge_cbh_bin_relative_interp[dumid_aad] = aad_cbh_bin_relative_interp[dumid_aad]\n",
    "            merge_detection_status[dumid_aad] = aad_detection_status[dumid_aad]\n",
    "            merge_cbh_1[dumid_aad] = aad_cbh_1[dumid_aad]\n",
    "            merge_cbh_2[dumid_aad] = aad_cbh_2[dumid_aad]\n",
    "            merge_cbh_3[dumid_aad] = aad_cbh_3[dumid_aad]\n",
    "            merge_source_ceil[dumid_aad] = 2\n",
    "    if False:\n",
    "        if np.size(dumid_arm) > 0.:\n",
    "            dumid_arm = np.squeeze(dumid_arm)\n",
    "            merge_cbh_bin_relative_interp[dumid_arm] = arm_cbh_bin_relative_interp[dumid_arm]\n",
    "            merge_detection_status[dumid_arm] = arm_detection_status[dumid_arm]\n",
    "            merge_cbh_1[dumid_arm] = arm_cbh_1[dumid_arm]\n",
    "            merge_cbh_2[dumid_arm] = arm_cbh_2[dumid_arm]\n",
    "            merge_cbh_3[dumid_arm] = arm_cbh_3[dumid_arm]    \n",
    "            merge_source_ceil[dumid_arm] = 1\n",
    "        \n",
    "\n",
    "    merge_ceil_out_dict = {'detection_status':merge_detection_status,\\\n",
    "                           'cbh_bin_relative_interp':merge_cbh_bin_relative_interp,\\\n",
    "                           'cbh_1':merge_cbh_1,\\\n",
    "                           'cbh_2':merge_cbh_2,\\\n",
    "                           'cbh_3':merge_cbh_3,\\\n",
    "                           'source_ceil':merge_source_ceil,\\\n",
    "                          }\n",
    "    \n",
    "    return merge_ceil_out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7b070a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================================\n",
    "# Main function to merge instruments\n",
    "#\n",
    "# Inputs: date -- from basta_dates_dt\n",
    "#         avg_bool -- boolean to perform averaging\n",
    "#==================================================\n",
    "def merge_instruments(date,basta_files,basta_dates_dt,avg_bool,arm_ceil_dates_dt,arm_files,aad_ceil_dates_dt,aad_ceil_files,sonde_dates_dt,sonde_files):\n",
    "    print('-------------------------------------------------')\n",
    "    print('-------------------------------------------------')\n",
    "    print('Date: ',date[0].strftime('%Y/%m/%d'))\n",
    "    print('-------------------------------------------------')\n",
    "    print('-------------------------------------------------')\n",
    "    \n",
    "    # Dictionary that will hold all merged data, separated by intrument\n",
    "    merged_dict = {}\n",
    "    \n",
    "    # Process BASTA data\n",
    "    start_time = time.time()\n",
    "    print('Processing BASTA data...')\n",
    "    basta_present_flag,basta_out_dict = process_basta(date,basta_dates_dt,basta_files,avg_bool)\n",
    "    if not basta_present_flag:\n",
    "        print('Bad radar data on this date. Skipping')\n",
    "        merged_dict = None\n",
    "        return basta_present_flag,merged_dict\n",
    "    else:\n",
    "        pass\n",
    "    merged_dict['basta'] = basta_out_dict\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print('Completed processing BASTA data. Time: {} seconds'.format(elapsed_time))\n",
    "    if not basta_present_flag:\n",
    "        print('No valid radar data on this date. Skipping')\n",
    "        return basta_present_flag\n",
    "    \n",
    "\n",
    "    # Process AAD CEIL data\n",
    "    start_time = time.time()\n",
    "    print('Processing Univ. of Canterbury (AAD) CEIL data...')\n",
    "    aad_ceil_present_flag,aad_ceil_out_dict = process_aad_ceil(date,aad_ceil_dates_dt,aad_ceil_files,avg_bool,basta_out_dict['height'],basta_out_dict['time_ts'],interp_backscatter=True)\n",
    "    if aad_ceil_present_flag:\n",
    "        merged_dict['aad_ceil'] = aad_ceil_out_dict\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print('Completed processing Univ. of Canterbury (AAD) CEIL data. Time: {} seconds'.format(elapsed_time))   \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Process ARM CEIL data\n",
    "    start_time = time.time()\n",
    "    print('Processing ARM CEIL data...')\n",
    "    arm_ceil_present_flag,arm_ceil_out_dict = process_arm_ceil(date,arm_ceil_dates_dt,arm_ceil_files,avg_bool,basta_out_dict['height'],basta_out_dict['time_ts'],interp_backscatter=True)\n",
    "    if arm_ceil_present_flag:\n",
    "        merged_dict['arm_ceil'] = arm_ceil_out_dict\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print('Completed processing ARM CEIL data. Time: {} seconds'.format(elapsed_time))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # Process Sounding data\n",
    "    start_time = time.time()\n",
    "    print('Processing native sonde data...')\n",
    "    sonde_present_flag,native_sonde_out_dict = process_native_sondes(date,sonde_dates_dt,sonde_times_dt,sonde_files,cluster_ids,cluster_times_dt)\n",
    "    if sonde_present_flag:\n",
    "        merged_dict['native_sonde'] = native_sonde_out_dict\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print('Completed processing native sonde data. Time: {} seconds'.format(elapsed_time))  \n",
    "        \n",
    "    # Interp Soundings\n",
    "    start_time = time.time()\n",
    "    print('Interpolating sonde data...')\n",
    "    interp_sonde_present_flag, interp_sonde_out_dict = interp_sondes(in_date,sonde_dates_dt,sonde_times_dt,sonde_files,merged_dict['basta']['time_dt'],merged_dict['basta']['height'],cluster_ids,cluster_times_dt)\n",
    "    if interp_sonde_present_flag:\n",
    "        merged_dict['interp_sonde'] = interp_sonde_out_dict\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print('Completed interpolation of sonde data. Time: {} seconds'.format(elapsed_time))  \n",
    "        \n",
    "    # Process SFC Met\n",
    "    start_time = time.time()\n",
    "    print('Processing sfc met data...')\n",
    "    sfc_met_present_flag,sfc_met_out_dict = process_sfc_met(date,sfc_dates_dt,sfc_files,avg_bool,basta_out_dict['time_ts'])\n",
    "    if sfc_met_present_flag:\n",
    "        merged_dict['sfc_met'] = sfc_met_out_dict\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print('Completed processing sfc met data. Time: {} seconds'.format(elapsed_time))         \n",
    "        \n",
    "    # Process satellite\n",
    "    start_time = time.time()\n",
    "    print('Processing satellite data...')\n",
    "    sat_present_flag,sat_out_dict = process_sat(date,sat_dates_dt,sat_files)\n",
    "\n",
    "    if sat_present_flag:\n",
    "        merged_dict['sat'] = sat_out_dict\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print('Completed processing satellite data. Time: {} seconds'.format(elapsed_time))   \n",
    "        \n",
    "    # Process PIRAT\n",
    "    start_time = time.time()\n",
    "    print('Processing PIRAT data...')\n",
    "    dis_present_flag,dis_out_dict = process_dis(date,dis_dates_dt,dis_files,avg_bool,basta_out_dict['time_ts'])\n",
    "    if dis_present_flag:\n",
    "        merged_dict['dis'] = dis_out_dict\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print('Completed processing PIRAT data. Time: {} seconds'.format(elapsed_time))  \n",
    "        \n",
    "    # Process Optics\n",
    "    start_time = time.time()\n",
    "    print('Processing optics data...')\n",
    "    optics_present_flag,optics_out_dict = process_optics(date,optics_dates_dt,optics_files,avg_bool,basta_out_dict['time_ts'])\n",
    "    if optics_present_flag:\n",
    "        merged_dict['optics'] = optics_out_dict\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print('Completed processing optics data. Time: {} seconds'.format(elapsed_time))  \n",
    "    \n",
    "    \n",
    "\n",
    "    # Merge ceilometers (prioritize AAD ceilometer)\n",
    "    if not aad_ceil_present_flag and not arm_ceil_present_flag:\n",
    "        # If neither ceilometer is present\n",
    "        merge_ceil_out_dict = None\n",
    "        merge_ceil_present_flag = False\n",
    "    elif aad_ceil_present_flag and not arm_ceil_present_flag:\n",
    "        # if AAD is only ceilometer present\n",
    "        merge_ceil_out_dict = {}\n",
    "        merge_ceil_out_dict['cbh_1'] = merged_dict['aad_ceil']['cbh_1']\n",
    "        merge_ceil_out_dict['cbh_2'] = merged_dict['aad_ceil']['cbh_2']\n",
    "        merge_ceil_out_dict['cbh_3'] = merged_dict['aad_ceil']['cbh_3']\n",
    "        merge_ceil_out_dict['detection_status'] = merged_dict['aad_ceil']['detection_status']\n",
    "        merge_ceil_out_dict['cbh_bin_relative_interp'] = merged_dict['aad_ceil']['cbh_bin_relative_interp']\n",
    "        dum = np.zeros(np.shape(merged_dict['aad_ceil']['detection_status']))\n",
    "        dum[:] = 2\n",
    "        merge_ceil_out_dict['source_ceil'] = dum\n",
    "        merge_ceil_present_flag = True\n",
    "        merged_dict['merge_ceil'] = merge_ceil_out_dict\n",
    "    elif not aad_ceil_present_flag and arm_ceil_present_flag:\n",
    "        # if ARM is only ceilometer present\n",
    "        merge_ceil_out_dict = {}\n",
    "        merge_ceil_out_dict['cbh_1'] = merged_dict['arm_ceil']['cbh_1']\n",
    "        merge_ceil_out_dict['cbh_2'] = merged_dict['arm_ceil']['cbh_2']\n",
    "        merge_ceil_out_dict['cbh_3'] = merged_dict['arm_ceil']['cbh_3']\n",
    "        merge_ceil_out_dict['detection_status'] = merged_dict['arm_ceil']['detection_status']\n",
    "        merge_ceil_out_dict['cbh_bin_relative_interp'] = merged_dict['arm_ceil']['cbh_bin_relative_interp']\n",
    "        dum = np.zeros(np.shape(merged_dict['arm_ceil']['detection_status']))\n",
    "        dum[:] = 1\n",
    "        merge_ceil_out_dict['source_ceil'] = dum\n",
    "        merge_ceil_present_flag = True\n",
    "        merged_dict['merge_ceil'] = merge_ceil_out_dict\n",
    "    elif aad_ceil_present_flag and arm_ceil_present_flag:\n",
    "        # if both ceilometers present\n",
    "        #merge_ceil_out_dict = {}\n",
    "        #merge_ceil_out_dict['cbh_1'] = merged_dict['aad_ceil']['cbh_1']\n",
    "        #merge_ceil_out_dict['cbh_2'] = merged_dict['aad_ceil']['cbh_2']\n",
    "        #merge_ceil_out_dict['cbh_3'] = merged_dict['aad_ceil']['cbh_3']\n",
    "        #merge_ceil_out_dict['detction_status'] = merged_dict['aad_ceil']['detection_status']\n",
    "        merge_ceil_out_dict = merge_ceil(merged_dict['aad_ceil'],merged_dict['arm_ceil'],merged_dict['basta']['time_dt'])\n",
    "        merge_ceil_present_flag = True\n",
    "        merged_dict['merge_ceil'] = merge_ceil_out_dict\n",
    "        #merge_ceil_out_dict = None\n",
    "        #merged_dict['merge_ceil'] = merge_ceil_out_dict\n",
    "        \n",
    "    # Dataset Flags\n",
    "    merged_dict['dataset_flags'] = {'basta':basta_present_flag,\\\n",
    "                                    'arm_ceil':arm_ceil_present_flag,\\\n",
    "                                    'aad_ceil':aad_ceil_present_flag,\\\n",
    "                                    'sfc_met':sfc_met_present_flag,\\\n",
    "                                    'dis':dis_present_flag,\\\n",
    "                                    'sat':sat_present_flag,\\\n",
    "                                    'merge_ceil':merge_ceil_present_flag,\\\n",
    "                                    'interp_sonde':interp_sonde_present_flag,\\\n",
    "                                    'optics':optics_present_flag,\\\n",
    "                                    'native_sonde':sonde_present_flag}\n",
    "       \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    return basta_present_flag,merged_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e3b1b7-3485-481a-80ec-287b74ca0eaa",
   "metadata": {},
   "source": [
    "# Main loop to merge instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b40982f6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/01/27\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.7709634304046631 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 42.07610487937927 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 0.00011372566223144531 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.2898678779602051 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 3\n",
      "Completed interpolation of sonde data. Time: 0.3427541255950928 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.07286572456359863 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 2.4031264781951904 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 0.00010085105895996094 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.0907893180847168 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/01/28\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.9123542308807373 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 26.054361581802368 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 9.179115295410156e-05 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.12731719017028809 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 3\n",
      "Completed interpolation of sonde data. Time: 0.31879401206970215 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.020517826080322266 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.24271106719970703 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 7.009506225585938e-05 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.07061648368835449 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/01/29\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.9692723751068115 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 24.71702241897583 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 0.00010323524475097656 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.1776137351989746 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 3\n",
      "Completed interpolation of sonde data. Time: 0.3333263397216797 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.07111120223999023 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.3309440612792969 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 0.00011515617370605469 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.07324767112731934 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/01/30\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.9334495067596436 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 23.84274196624756 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 0.00010275840759277344 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.14297008514404297 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 3\n",
      "Completed interpolation of sonde data. Time: 0.33380770683288574 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.03177928924560547 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.28595638275146484 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 9.751319885253906e-05 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.07677030563354492 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/01/31\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.8701667785644531 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 23.12611198425293 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 0.00012922286987304688 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.2782299518585205 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 3\n",
      "Completed interpolation of sonde data. Time: 0.3461573123931885 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.023988962173461914 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.33585405349731445 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 0.00010514259338378906 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.06723141670227051 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/02/01\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.9265859127044678 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 19.14908504486084 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 8.702278137207031e-05 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.1918201446533203 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 3\n",
      "Completed interpolation of sonde data. Time: 0.3345963954925537 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.054125308990478516 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.3240058422088623 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 0.00010204315185546875 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.07178616523742676 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/02/02\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.9080159664154053 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 25.296875715255737 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 0.00011897087097167969 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.14493489265441895 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 3\n",
      "Completed interpolation of sonde data. Time: 0.3180661201477051 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.0565948486328125 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.30855488777160645 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 0.00010013580322265625 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.0838167667388916 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/02/03\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.8792352676391602 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 26.193745136260986 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 9.751319885253906e-05 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.2244710922241211 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 3\n",
      "Completed interpolation of sonde data. Time: 0.34266042709350586 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.04914522171020508 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.8858206272125244 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 0.0001010894775390625 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.07140254974365234 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/02/04\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 1.3610098361968994 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 24.039071798324585 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 0.00012445449829101562 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.2684779167175293 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 3\n",
      "Completed interpolation of sonde data. Time: 0.3454563617706299 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.023042917251586914 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.36771607398986816 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 8.273124694824219e-05 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.06338715553283691 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/02/05\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.8716421127319336 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 66.5196692943573 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 6.818771362304688e-05 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.13013601303100586 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 2\n",
      "Completed interpolation of sonde data. Time: 0.29935622215270996 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.05364084243774414 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.2770881652832031 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 8.940696716308594e-05 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.06885623931884766 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/02/06\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.848334789276123 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 20.82772135734558 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 9.417533874511719e-05 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.16831135749816895 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 2\n",
      "Completed interpolation of sonde data. Time: 0.3168373107910156 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.023908138275146484 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 1.0540838241577148 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 8.249282836914062e-05 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.07836294174194336 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/02/07\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.9020352363586426 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 26.490846872329712 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 8.249282836914062e-05 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.02258920669555664 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 1\n",
      "Completed interpolation of sonde data. Time: 0.265932559967041 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.07646799087524414 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.3501863479614258 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 8.940696716308594e-05 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.07909011840820312 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/02/08\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 1.0805976390838623 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 24.950294017791748 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 0.00010275840759277344 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.14881229400634766 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 1\n",
      "Completed interpolation of sonde data. Time: 0.2515285015106201 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.08095812797546387 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.28380370140075684 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 8.320808410644531e-05 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.06692147254943848 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/02/09\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.9626147747039795 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 22.744309186935425 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 8.416175842285156e-05 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.21533656120300293 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 2\n",
      "Completed interpolation of sonde data. Time: 0.3156471252441406 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.07292795181274414 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.36666202545166016 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 0.00010848045349121094 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.10117888450622559 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/02/10\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.8804323673248291 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 23.558409929275513 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 7.82012939453125e-05 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.19494915008544922 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 3\n",
      "Completed interpolation of sonde data. Time: 0.33740234375 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.06616544723510742 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.2966945171356201 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 9.226799011230469e-05 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.07063460350036621 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/02/11\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.7866108417510986 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 5.698204040527344e-05 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 4.506111145019531e-05 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.14618802070617676 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 3\n",
      "Completed interpolation of sonde data. Time: 0.3283870220184326 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.022960901260375977 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.25266289710998535 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 8.535385131835938e-05 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.06316494941711426 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/02/12\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.8417487144470215 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 6.899151802062988 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 7.724761962890625e-05 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.21501874923706055 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 3\n",
      "Completed interpolation of sonde data. Time: 0.34983205795288086 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.026154279708862305 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.24850153923034668 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 8.416175842285156e-05 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.06607222557067871 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/02/13\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.8636620044708252 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 24.6557195186615 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 0.00010395050048828125 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.19691753387451172 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 3\n",
      "Completed interpolation of sonde data. Time: 0.3357970714569092 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.026357173919677734 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.29590272903442383 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 9.322166442871094e-05 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.06899452209472656 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/02/14\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.8525059223175049 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 25.625024557113647 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 8.034706115722656e-05 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.11477828025817871 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 2\n",
      "Completed interpolation of sonde data. Time: 0.30240368843078613 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.0686943531036377 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.32268261909484863 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 6.29425048828125e-05 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.07337546348571777 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/02/15\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.8713996410369873 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 21.72224235534668 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 0.00010609626770019531 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.16181516647338867 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 2\n",
      "Completed interpolation of sonde data. Time: 0.31187939643859863 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.06803011894226074 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.2643156051635742 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 0.0001068115234375 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.07630538940429688 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/02/16\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.8874373435974121 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 31.520617723464966 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 9.179115295410156e-05 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.22643566131591797 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 3\n",
      "Completed interpolation of sonde data. Time: 0.34701967239379883 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.07070755958557129 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.29168200492858887 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 0.00010156631469726562 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.06796503067016602 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/02/17\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 1.008946180343628 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 17.589235305786133 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 0.000110626220703125 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.26024532318115234 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 3\n",
      "Completed interpolation of sonde data. Time: 0.3430478572845459 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.03459954261779785 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.2566866874694824 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 0.00011014938354492188 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.07820796966552734 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/02/18\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.8356256484985352 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 33.89277720451355 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 9.012222290039062e-05 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.24442434310913086 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 3\n",
      "Completed interpolation of sonde data. Time: 0.33839964866638184 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.06451749801635742 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.2999539375305176 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 7.677078247070312e-05 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.07257246971130371 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/02/19\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.8328042030334473 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 36.25380206108093 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 8.392333984375e-05 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.14269709587097168 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 3\n",
      "Completed interpolation of sonde data. Time: 0.3173999786376953 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.022222042083740234 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.2476191520690918 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 8.344650268554688e-05 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.07297253608703613 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/02/20\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.8893430233001709 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 24.002671718597412 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 0.00012612342834472656 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.2041611671447754 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 3\n",
      "Completed interpolation of sonde data. Time: 0.3371469974517822 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.06990623474121094 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.32068753242492676 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 7.462501525878906e-05 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.07079958915710449 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/02/21\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.8426394462585449 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 25.8793466091156 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 0.00010156631469726562 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.18636345863342285 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 3\n",
      "Completed interpolation of sonde data. Time: 0.3345947265625 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.06345176696777344 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.2781853675842285 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 9.584426879882812e-05 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.06231188774108887 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/02/22\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.9718723297119141 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 23.725565433502197 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 1.7803258895874023 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.09192609786987305 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 2\n",
      "Completed interpolation of sonde data. Time: 0.3118445873260498 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.01951146125793457 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.2890796661376953 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 9.870529174804688e-05 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.05954098701477051 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/02/23\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.8577654361724854 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 40.54339575767517 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 3.3618929386138916 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.20058178901672363 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 3\n",
      "Completed interpolation of sonde data. Time: 0.3400382995605469 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.02671217918395996 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.25786375999450684 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 0.0001049041748046875 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.06574726104736328 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/02/24\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.863379955291748 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 21.22077775001526 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 3.2262990474700928 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.19755101203918457 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 3\n",
      "Completed interpolation of sonde data. Time: 0.327817440032959 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.01980137825012207 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.27826476097106934 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 0.00010824203491210938 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.07952666282653809 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/02/25\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.9319231510162354 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 19.500508785247803 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 3.2390964031219482 seconds\n",
      "Processing native sonde data...\n",
      "Sonde failed to reach 10 km. Therefore omitting this sounding.\n",
      "Completed processing native sonde data. Time: 0.13685989379882812 seconds\n",
      "Interpolating sonde data...\n",
      "Sonde failed to reach 10 km. Therefore omitting this sounding.\n",
      "# of current soundings: 2\n",
      "Completed interpolation of sonde data. Time: 0.3082435131072998 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.02736496925354004 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.37395358085632324 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 0.00011134147644042969 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.06619811058044434 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/02/26\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.9256188869476318 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 27.55910897254944 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 3.681056499481201 seconds\n",
      "Processing native sonde data...\n",
      "Sonde failed to reach 10 km. Therefore omitting this sounding.\n",
      "Completed processing native sonde data. Time: 0.22057390213012695 seconds\n",
      "Interpolating sonde data...\n",
      "Sonde failed to reach 10 km. Therefore omitting this sounding.\n",
      "# of current soundings: 2\n",
      "Completed interpolation of sonde data. Time: 0.32728052139282227 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.042063236236572266 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.2456214427947998 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 0.00010442733764648438 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.09600186347961426 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/02/27\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.8853759765625 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 24.87431263923645 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 3.344298839569092 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.1848909854888916 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 3\n",
      "Completed interpolation of sonde data. Time: 0.3405587673187256 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.03565406799316406 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.2639942169189453 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 8.392333984375e-05 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.06673979759216309 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/02/28\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.8664994239807129 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 20.17331075668335 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 3.2983670234680176 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.25879526138305664 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 3\n",
      "Completed interpolation of sonde data. Time: 0.3407771587371826 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.04220914840698242 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.24359798431396484 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 5.841255187988281e-05 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.06310844421386719 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/03/01\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.8964917659759521 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 35.22546172142029 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 3.3196868896484375 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.21736454963684082 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 3\n",
      "Completed interpolation of sonde data. Time: 0.350985050201416 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.03727316856384277 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.23899483680725098 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 9.989738464355469e-05 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.06217622756958008 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/03/02\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.8666970729827881 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 24.879608631134033 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 3.35322904586792 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.14037108421325684 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 3\n",
      "Completed interpolation of sonde data. Time: 0.3272206783294678 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.020828723907470703 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.2507045269012451 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 9.799003601074219e-05 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.06565356254577637 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/03/03\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.9231986999511719 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 21.548539876937866 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 3.426830768585205 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.15320897102355957 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 3\n",
      "Completed interpolation of sonde data. Time: 0.3353588581085205 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.03880572319030762 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.8495924472808838 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 0.00011157989501953125 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.10381054878234863 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/03/04\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.9225575923919678 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 18.33859419822693 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 3.3839712142944336 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.20483040809631348 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 3\n",
      "Completed interpolation of sonde data. Time: 0.34508514404296875 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.030469655990600586 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.3125166893005371 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 0.00010919570922851562 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.0786893367767334 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/03/05\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.7992446422576904 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 17.33364725112915 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 3.254323720932007 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.2675793170928955 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 3\n",
      "Completed interpolation of sonde data. Time: 0.3400874137878418 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.04715466499328613 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.2401447296142578 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 8.296966552734375e-05 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.07160019874572754 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/03/06\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.8605437278747559 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 21.85129165649414 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 3.4876370429992676 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.19770407676696777 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 3\n",
      "Completed interpolation of sonde data. Time: 0.34304094314575195 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.02357959747314453 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.25768470764160156 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 6.389617919921875e-05 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.08176016807556152 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/03/07\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.8034646511077881 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 18.363922357559204 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 3.2400310039520264 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.18280768394470215 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 3\n",
      "Completed interpolation of sonde data. Time: 0.3314249515533447 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.05267620086669922 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.28022098541259766 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 5.745887756347656e-05 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.06495189666748047 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/03/08\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.8603475093841553 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 18.879204511642456 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 3.2650012969970703 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.2730112075805664 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 3\n",
      "Completed interpolation of sonde data. Time: 0.3393089771270752 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.0355677604675293 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.2655036449432373 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 8.440017700195312e-05 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.06896209716796875 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/03/09\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 1.1328227519989014 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 23.777274131774902 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 3.6010026931762695 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.21805071830749512 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 3\n",
      "Completed interpolation of sonde data. Time: 0.36490464210510254 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.05019688606262207 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.3269345760345459 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 7.534027099609375e-05 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.06891679763793945 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/03/10\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.9174675941467285 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 27.79786515235901 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 3.6388156414031982 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.23341941833496094 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 3\n",
      "Completed interpolation of sonde data. Time: 0.37092089653015137 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.023962974548339844 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.273343563079834 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 7.319450378417969e-05 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.07317805290222168 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/03/11\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.9408085346221924 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 32.7430579662323 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 3.6460013389587402 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.21080923080444336 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 3\n",
      "Completed interpolation of sonde data. Time: 0.37981319427490234 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.052802085876464844 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.28352880477905273 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 8.440017700195312e-05 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.06843280792236328 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/03/12\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.9671807289123535 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 24.305014610290527 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 3.558842420578003 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.1473073959350586 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 3\n",
      "Completed interpolation of sonde data. Time: 0.3598616123199463 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.383056640625 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.32042717933654785 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 7.319450378417969e-05 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.07952046394348145 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/03/13\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.8173110485076904 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 118.67112588882446 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 3.6247923374176025 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.18808484077453613 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 3\n",
      "Completed interpolation of sonde data. Time: 0.36019396781921387 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.08922481536865234 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.2796139717102051 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 6.914138793945312e-05 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 0.07018327713012695 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/03/14\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.9699833393096924 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 22.340290784835815 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 3.564239740371704 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.17689180374145508 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 3\n",
      "Completed interpolation of sonde data. Time: 0.35336995124816895 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.025005102157592773 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.2883903980255127 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 9.799003601074219e-05 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 7.462501525878906e-05 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/03/15\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.9142971038818359 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 24.55369210243225 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 3.6102561950683594 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.535111665725708 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 2\n",
      "Completed interpolation of sonde data. Time: 0.3382387161254883 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.026667356491088867 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.2974567413330078 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 0.00010156631469726562 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 8.678436279296875e-05 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/03/16\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.9732322692871094 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 23.487687349319458 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 3.567373275756836 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.08760190010070801 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 1\n",
      "Completed interpolation of sonde data. Time: 0.2958104610443115 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.027798891067504883 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.3119995594024658 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 8.034706115722656e-05 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 5.984306335449219e-05 seconds\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Date:  2017/03/17\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Processing BASTA data...\n",
      "Completed processing BASTA data. Time: 0.6675117015838623 seconds\n",
      "Processing Univ. of Canterbury (AAD) CEIL data...\n",
      "Completed processing Univ. of Canterbury (AAD) CEIL data. Time: 19.408682107925415 seconds\n",
      "Processing ARM CEIL data...\n",
      "Completed processing ARM CEIL data. Time: 2.660677433013916 seconds\n",
      "Processing native sonde data...\n",
      "Completed processing native sonde data. Time: 0.2091975212097168 seconds\n",
      "Interpolating sonde data...\n",
      "# of current soundings: 3\n",
      "Completed interpolation of sonde data. Time: 0.2884206771850586 seconds\n",
      "Processing sfc met data...\n",
      "Completed processing sfc met data. Time: 0.03336310386657715 seconds\n",
      "Processing satellite data...\n",
      "Completed processing satellite data. Time: 0.27271318435668945 seconds\n",
      "Processing PIRAT data...\n",
      "Completed processing PIRAT data. Time: 5.745887756347656e-05 seconds\n",
      "Processing optics data...\n",
      "Completed processing optics data. Time: 4.3392181396484375e-05 seconds\n"
     ]
    }
   ],
   "source": [
    "# Note: avg_bool was a placeholder that was meant to temporally average data, but this feature was never implemented.\n",
    "for date in basta_dates_dt:\n",
    "    in_date = [date]\n",
    "    basta_present_flag,merged_dict = merge_instruments(in_date,basta_files,basta_dates_dt,False,arm_ceil_dates_dt,arm_ceil_files,aad_ceil_dates_dt,aad_ceil_files,sonde_dates_dt,sonde_files)\n",
    "    if basta_present_flag:\n",
    "        save_path = '/mnt/raid/mwstanfo/micre/merged_instrument_files/'\n",
    "        dum_time_str = in_date[0].strftime('%Y%m%d')\n",
    "        out_pkl_file = save_path+'merged_instruments_{}.p'.format(dum_time_str)\n",
    "        pickle.dump(merged_dict,open(out_pkl_file,\"wb\"))\n",
    "        #print(aaaa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa52e926-d09d-490a-9d05-f7257273dc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#target_date = datetime.datetime(2016,5,22)\n",
    "#dumid = np.where(basta_dates_dt == target_date)\n",
    "#in_date = basta_dates_dt[dumid[0]]\n",
    "#basta_present_flag,merged_dict = merge_instruments(in_date,basta_files,basta_dates_dt,False,arm_ceil_dates_dt,arm_ceil_files,aad_ceil_dates_dt,aad_ceil_files,sonde_dates_dt,sonde_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c26641-ff4d-4d85-9150-bd76f19ba4b0",
   "metadata": {},
   "source": [
    "# Everything below is diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d78f0b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dum_cbh = merged_dict['arm_ceil']['cbh_1']\n",
    "dum_ds = merged_dict['arm_ceil']['detection_status']\n",
    "dumid = np.where(dum_ds == 0.)\n",
    "print('Detection Status 0:',np.unique(dum_cbh[dumid]))\n",
    "dumid = np.where(dum_ds == 1.)\n",
    "print('Detection Status 1:',np.unique(dum_cbh[dumid]))\n",
    "dumid = np.where(dum_ds == 2.)\n",
    "print('Detection Status 2:',np.unique(dum_cbh[dumid]))\n",
    "dumid = np.where(dum_ds == 3.)\n",
    "print('Detection Status 3:',np.unique(dum_cbh[dumid]))\n",
    "dumid = np.where(dum_ds == 4.)\n",
    "print('Detection Status 4:',np.unique(dum_cbh[dumid]))\n",
    "dumid = np.where(dum_ds == 5.)\n",
    "print('Detection Status 5:',np.unique(dum_cbh[dumid]))\n",
    "dumid = np.where(np.isnan(dum_ds))\n",
    "print('Detection Status NaN:',np.unique(dum_cbh[dumid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e7ba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "dum_cbh = merged_dict['aad_ceil']['cbh_1']\n",
    "dum_ds = merged_dict['aad_ceil']['detection_status']\n",
    "dumid = np.where(dum_ds == 0.)\n",
    "print('Detection Status 0:',np.unique(dum_cbh[dumid]))\n",
    "dumid = np.where(dum_ds == 1.)\n",
    "print('Detection Status 1:',np.unique(dum_cbh[dumid]))\n",
    "dumid = np.where(dum_ds == 2.)\n",
    "print('Detection Status 2:',np.unique(dum_cbh[dumid]))\n",
    "dumid = np.where(dum_ds == 3.)\n",
    "print('Detection Status 3:',np.unique(dum_cbh[dumid]))\n",
    "dumid = np.where(dum_ds == 4.)\n",
    "print('Detection Status 4:',np.unique(dum_cbh[dumid]))\n",
    "dumid = np.where(dum_ds == 5.)\n",
    "print('Detection Status 5:',np.unique(dum_cbh[dumid]))\n",
    "dumid = np.where(np.isnan(dum_ds))\n",
    "print('Detection Status NaN:',np.unique(dum_cbh[dumid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f0c0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dum_cbh = merged_dict['merge_ceil']['cbh_1']\n",
    "dum_ds = merged_dict['merge_ceil']['detection_status']\n",
    "dumid = np.where(dum_ds == 0.)\n",
    "print('Detection Status 0:',np.unique(dum_cbh[dumid]))\n",
    "dumid = np.where(dum_ds == 1.)\n",
    "print('Detection Status 1:',np.unique(dum_cbh[dumid]))\n",
    "dumid = np.where(dum_ds == 2.)\n",
    "print('Detection Status 2:',np.unique(dum_cbh[dumid]))\n",
    "dumid = np.where(dum_ds == 3.)\n",
    "print('Detection Status 3:',np.unique(dum_cbh[dumid]))\n",
    "dumid = np.where(dum_ds == 4.)\n",
    "print('Detection Status 4:',np.unique(dum_cbh[dumid]))\n",
    "dumid = np.where(dum_ds == 5.)\n",
    "print('Detection Status 5:',np.unique(dum_cbh[dumid]))\n",
    "dumid = np.where(np.isnan(dum_ds))\n",
    "print('Detection Status NaN:',np.unique(dum_cbh[dumid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d670aa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------\n",
    "# Plot to check interpolation of ARM CEIL beta_att\n",
    "# to radar time-height grid\n",
    "#----------------------------------------------------\n",
    "fig = plt.figure(figsize=(14,12))\n",
    "ax1=fig.add_subplot(311)\n",
    "ax2=fig.add_subplot(312)\n",
    "ax3=fig.add_subplot(313)\n",
    "axlist = [ax1,ax2,ax3]\n",
    "Fontsize=14\n",
    "dfmt = mdates.DateFormatter('%H:%M')\n",
    "\n",
    "\n",
    "# Plot Reflectivity\n",
    "dum_ref = merged_dict['basta']['ref'].copy()\n",
    "dum_ref[(dum_ref > -999.) & (dum_ref < -50.)] = -50.\n",
    "dum_ref[dum_ref > 20.] = 20.\n",
    "cmap = matplotlib.cm.get_cmap(\"nipy_spectral\").copy()\n",
    "cmap.set_under('w')\n",
    "cmap.set_bad('grey')\n",
    "basta_bin_edges = np.arange(0,np.max(merged_dict['basta']['height'])+12.5+25.,25.)\n",
    "dumid = np.where(merged_dict['basta']['height'] <= dum_y_lim*1.e3)\n",
    "dumid = np.squeeze(dumid)\n",
    "\n",
    "ref_plot = ax1.pcolormesh(merged_dict['basta']['time_dt'],\\\n",
    "                            merged_dict['basta']['height'][dumid]/1.e3,\\\n",
    "                            dum_ref[dumid,:],\\\n",
    "                            cmap=cmap,\\\n",
    "                            vmin=-50.1,vmax=20.1)            \n",
    "ref_cbar = fig.colorbar(ref_plot,ax=ax1,pad=0.005)\n",
    "ref_cbar.ax.set_ylabel('Reflectivity [dBZ]',fontsize=Fontsize)\n",
    "ref_cbar.ax.tick_params(labelsize=Fontsize)\n",
    "if np.all(merged_dict['arm_ceil']['cbh_1'] != np.nan):\n",
    "    ax1.scatter(merged_dict['basta']['time_dt'],merged_dict['arm_ceil']['cbh_1']*1.e-3,s=2,c='k',label='CBH1')\n",
    "if np.all(merged_dict['arm_ceil']['cbh_2'] != np.nan):\n",
    "    ax1.scatter(merged_dict['basta']['time_dt'],merged_dict['arm_ceil']['cbh_2']*1.e-3,s=2,c='magenta',label='CBH2')\n",
    "if np.all(merged_dict['arm_ceil']['cbh_3'] != np.nan):\n",
    "    ax1.scatter(merged_dict['basta']['time_dt'],merged_dict['arm_ceil']['cbh_3']*1.e-3,s=2,c='cyan',label='CBH3')\n",
    "ax1.legend(fontsize=Fontsize,loc='upper left',ncol=1)\n",
    "\n",
    "# Plot Attenuated Backscatter\n",
    "dum_arm_ceil_backscatter = merged_dict['arm_ceil']['native_backscatter'].copy()\n",
    "cmap = matplotlib.cm.get_cmap(\"jet\").copy()\n",
    "cmap.set_under('navy')\n",
    "cmap.set_bad('grey')\n",
    "dum_arm_ceil_backscatter[dum_arm_ceil_backscatter < -8.] = -8.\n",
    "dum_arm_ceil_backscatter[dum_arm_ceil_backscatter > -3.] = -3.\n",
    "dumid = np.where(merged_dict['aad_ceil']['native_range'] <= dum_y_lim*1.e3)\n",
    "dumid = np.squeeze(dumid)\n",
    "ceil_backscatter_plot = ax2.pcolormesh(merged_dict['arm_ceil']['native_time_dt'],\\\n",
    "                                     merged_dict['arm_ceil']['native_range'][dumid]*1.e-3,\\\n",
    "                                     np.transpose(dum_arm_ceil_backscatter[:,dumid]),\\\n",
    "                                     cmap=cmap,\n",
    "                                     vmin=-8,vmax=-3)\n",
    "dum_ticks = [-8,-7,-6,-5,-4,-3]\n",
    "ceil_backscatter_cbar = fig.colorbar(ceil_backscatter_plot,ax=ax2,pad=0.005,ticks=dum_ticks)\n",
    "ceil_backscatter_cbar.ax.set_ylabel('$log_{10}$($\\\\beta_{att}$) [sr$^{-1}$ m$^{-1}$]',fontsize=Fontsize)\n",
    "ceil_backscatter_cbar.ax.tick_params(labelsize=Fontsize)\n",
    "\n",
    "\n",
    "if np.all(merged_dict['arm_ceil']['native_cbh_1'] != np.nan):\n",
    "    ax2.scatter(merged_dict['arm_ceil']['native_time_dt'],merged_dict['arm_ceil']['native_cbh_1']*1.e-3,s=2,c='k',label='CBH1')\n",
    "if np.all(merged_dict['arm_ceil']['native_cbh_2'] != np.nan):\n",
    "    ax2.scatter(merged_dict['arm_ceil']['native_time_dt'],merged_dict['arm_ceil']['native_cbh_2']*1.e-3,s=2,c='magenta',label='CBH2')\n",
    "if np.all(merged_dict['arm_ceil']['native_cbh_3'] != np.nan):\n",
    "    ax2.scatter(merged_dict['arm_ceil']['native_time_dt'],merged_dict['arm_ceil']['native_cbh_3']*1.e-3,s=2,c='cyan',label='CBH3')\n",
    "ax2.legend(fontsize=Fontsize,loc='upper left',ncol=1)\n",
    "        \n",
    "# Plot Interpolated Attenuated Backscatter\n",
    "cmap = matplotlib.cm.get_cmap(\"jet\").copy()\n",
    "cmap.set_under('navy')\n",
    "cmap.set_bad('grey')\n",
    "dumid = np.where(merged_dict['basta']['height'] <= dum_y_lim*1.e3)\n",
    "dumid = np.squeeze(dumid)\n",
    "ceil_backscatter_interp_plot = ax3.pcolormesh(merged_dict['basta']['time_dt'],\\\n",
    "                                     merged_dict['arm_ceil']['interp_height'][dumid]*1.e-3,\\\n",
    "                                     merged_dict['arm_ceil']['backscatter'][dumid,:],\\\n",
    "                                     cmap=cmap,\n",
    "                                     vmin=-8,vmax=-3)\n",
    "dum_ticks = [-8,-7,-6,-5,-4,-3]\n",
    "ceil_backscatter_interp_cbar = fig.colorbar(ceil_backscatter_interp_plot,ax=ax3,pad=0.005,ticks=dum_ticks)\n",
    "ceil_backscatter_interp_cbar.ax.set_ylabel('$log_{10}$($\\\\beta_{att}$) [sr$^{-1}$ m$^{-1}$]',fontsize=Fontsize)\n",
    "ceil_backscatter_interp_cbar.ax.tick_params(labelsize=Fontsize)\n",
    "\n",
    "if np.all(merged_dict['arm_ceil']['cbh_1'] != np.nan):\n",
    "    ax3.scatter(merged_dict['basta']['time_dt'],merged_dict['arm_ceil']['cbh_1']*1.e-3,s=2,c='k',label='CBH1')\n",
    "if np.all(merged_dict['arm_ceil']['cbh_2'] != np.nan):\n",
    "    ax3.scatter(merged_dict['basta']['time_dt'],merged_dict['arm_ceil']['cbh_2']*1.e-3,s=2,c='magenta',label='CBH2')\n",
    "if np.all(merged_dict['arm_ceil']['cbh_3'] != np.nan):\n",
    "    ax3.scatter(merged_dict['basta']['time_dt'],merged_dict['arm_ceil']['cbh_3']*1.e-3,s=2,c='cyan',label='CBH3')\n",
    "ax3.legend(fontsize=Fontsize,loc='upper left',ncol=1)\n",
    "\n",
    "\n",
    "\n",
    "for ax in axlist:\n",
    "    ax.set_ylabel('Height [km]',fontsize=Fontsize)\n",
    "    ax.set_xlabel('UTC Time [HH:MM]',fontsize=Fontsize)\n",
    "    ax.tick_params(labelsize=Fontsize)\n",
    "    ax.xaxis.set_major_formatter(dfmt)\n",
    "    ax.grid(True)\n",
    "    ax.set_ylim(0,1)\n",
    "    \n",
    "ax1.set_title('BASTA Reflectivity',fontsize=Fontsize*1.25,fontweight='bold')\n",
    "dumstr = '$log_{10}$($\\\\beta_{att}$)'\n",
    "ax2.set_title('ARM CEIL Native {}'.format(dumstr),fontsize=Fontsize*1.25,fontweight='bold')\n",
    "ax3.set_title('ARM CEIL Interpolated {}'.format(dumstr),fontsize=Fontsize*1.25,fontweight='bold')\n",
    "    \n",
    "datestr = datetime.datetime(basta_time_dt[0].year,basta_time_dt[0].month,basta_time_dt[0].day).strftime(\"%m/%d/%Y\")\n",
    "plt.suptitle(datestr,fontsize=Fontsize*2)\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9a9751",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------\n",
    "# Plot to check interpolation of Univ. of Canterbury\n",
    "# CEIL beta_att to radar time-height grid\n",
    "#----------------------------------------------------\n",
    "fig = plt.figure(figsize=(14,12))\n",
    "ax1=fig.add_subplot(311)\n",
    "ax2=fig.add_subplot(312)\n",
    "ax3=fig.add_subplot(313)\n",
    "axlist = [ax1,ax2,ax3]\n",
    "Fontsize=14\n",
    "dfmt = mdates.DateFormatter('%H:%M')\n",
    "\n",
    "dum_y_lim = 1.\n",
    "# Plot Reflectivity\n",
    "dum_ref = merged_dict['basta']['ref'].copy()\n",
    "dum_ref[(dum_ref > -999.) & (dum_ref < -50.)] = -50.\n",
    "dum_ref[dum_ref > 20.] = 20.\n",
    "cmap = matplotlib.cm.get_cmap(\"nipy_spectral\").copy()\n",
    "cmap.set_under('w')\n",
    "cmap.set_bad('grey')\n",
    "dumid = np.where(merged_dict['basta']['height'] <= dum_y_lim*1.e3)\n",
    "dumid = np.squeeze(dumid)\n",
    "\n",
    "basta_bin_edges = np.arange(0,np.max(merged_dict['basta']['height'])+12.5+25.,25.)\n",
    "ref_plot = ax1.pcolormesh(merged_dict['basta']['time_dt'],\\\n",
    "                            merged_dict['basta']['height'][dumid]/1.e3,\\\n",
    "                            dum_ref[dumid,:],\\\n",
    "                            cmap=cmap,\\\n",
    "                            vmin=-50.1,vmax=20.1)\n",
    "ref_cbar = fig.colorbar(ref_plot,ax=ax1,pad=0.005)\n",
    "ref_cbar.ax.set_ylabel('Reflectivity [dBZ]',fontsize=Fontsize)\n",
    "ref_cbar.ax.tick_params(labelsize=Fontsize)\n",
    "if np.all(merged_dict['aad_ceil']['cbh_1'] != np.nan):\n",
    "    ax1.scatter(merged_dict['basta']['time_dt'],merged_dict['aad_ceil']['cbh_1']*1.e-3,s=2,c='k',label='CBH1')\n",
    "if np.all(merged_dict['aad_ceil']['cbh_2'] != np.nan):\n",
    "    ax1.scatter(merged_dict['basta']['time_dt'],merged_dict['aad_ceil']['cbh_2']*1.e-3,s=2,c='magenta',label='CBH2')\n",
    "if np.all(merged_dict['aad_ceil']['cbh_3'] != np.nan):\n",
    "    ax1.scatter(merged_dict['basta']['time_dt'],merged_dict['aad_ceil']['cbh_3']*1.e-3,s=2,c='cyan',label='CBH3')\n",
    "ax1.legend(fontsize=Fontsize,loc='upper left',ncol=1)\n",
    "\n",
    "\n",
    "# Plot Attenuated Backscatter\n",
    "dum_aad_ceil_backscatter = merged_dict['aad_ceil']['native_backscatter'].copy()\n",
    "cmap = matplotlib.cm.get_cmap(\"jet\").copy()\n",
    "cmap.set_under('navy')\n",
    "cmap.set_bad('grey')\n",
    "dum_aad_ceil_backscatter[dum_aad_ceil_backscatter < -8.] = -8.\n",
    "dum_aad_ceil_backscatter[dum_aad_ceil_backscatter > -3.] = -3.\n",
    "dumid = np.where(merged_dict['aad_ceil']['native_range'] <= dum_y_lim*1.e3)\n",
    "dumid = np.squeeze(dumid)\n",
    "ceil_backscatter_plot = ax2.pcolormesh(merged_dict['aad_ceil']['native_time_dt'],\\\n",
    "                                     merged_dict['aad_ceil']['native_range'][dumid]*1.e-3,\\\n",
    "                                     np.transpose(dum_aad_ceil_backscatter[:,dumid]),\\\n",
    "                                     cmap=cmap,\n",
    "                                     vmin=-8,vmax=-3)\n",
    "dum_ticks = [-8,-7,-6,-5,-4,-3]\n",
    "\n",
    "ceil_backscatter_cbar = fig.colorbar(ceil_backscatter_plot,ax=ax2,pad=0.005,ticks=dum_ticks)\n",
    "ceil_backscatter_cbar.ax.set_ylabel('$log_{10}$($\\\\beta_{att}$) [sr$^{-1}$ m$^{-1}$]',fontsize=Fontsize)\n",
    "ceil_backscatter_cbar.ax.tick_params(labelsize=Fontsize)\n",
    "if np.all(merged_dict['aad_ceil']['native_cbh_1'] != np.nan):\n",
    "    ax2.scatter(merged_dict['aad_ceil']['native_time_dt'],merged_dict['aad_ceil']['native_cbh_1']*1.e-3,s=2,c='k',label='CBH1')\n",
    "if np.all(merged_dict['aad_ceil']['native_cbh_2'] != np.nan):\n",
    "    ax2.scatter(merged_dict['aad_ceil']['native_time_dt'],merged_dict['aad_ceil']['native_cbh_2']*1.e-3,s=2,c='magenta',label='CBH2')\n",
    "if np.all(merged_dict['aad_ceil']['native_cbh_3'] != np.nan):\n",
    "    ax2.scatter(merged_dict['aad_ceil']['native_time_dt'],merged_dict['aad_ceil']['native_cbh_3']*1.e-3,s=2,c='cyan',label='CBH3')\n",
    "ax2.legend(fontsize=Fontsize,loc='upper left',ncol=1)\n",
    "        \n",
    "# Plot Interpolated Attenuated Backscatter\n",
    "cmap = matplotlib.cm.get_cmap(\"jet\").copy()\n",
    "cmap.set_under('navy')\n",
    "cmap.set_bad('grey')\n",
    "dumid = np.where(merged_dict['basta']['height'] <= dum_y_lim*1.e3)\n",
    "dumid = np.squeeze(dumid)\n",
    "\n",
    "ceil_backscatter_interp_plot = ax3.pcolormesh(merged_dict['basta']['time_dt'],\\\n",
    "                                     merged_dict['aad_ceil']['interp_height'][dumid]*1.e-3,\\\n",
    "                                     merged_dict['aad_ceil']['backscatter'][dumid,:],\\\n",
    "                                     cmap=cmap,\n",
    "                                     vmin=-8,vmax=-3)\n",
    "dum_ticks = [-8,-7,-6,-5,-4,-3]\n",
    "ceil_backscatter_interp_cbar = fig.colorbar(ceil_backscatter_interp_plot,ax=ax3,pad=0.005,ticks=dum_ticks)\n",
    "ceil_backscatter_interp_cbar.ax.set_ylabel('$log_{10}$($\\\\beta_{att}$) [sr$^{-1}$ m$^{-1}$]',fontsize=Fontsize)\n",
    "ceil_backscatter_interp_cbar.ax.tick_params(labelsize=Fontsize)\n",
    "\n",
    "if np.all(merged_dict['aad_ceil']['cbh_1'] != np.nan):\n",
    "    ax3.scatter(merged_dict['basta']['time_dt'],merged_dict['aad_ceil']['cbh_1']*1.e-3,s=2,c='k',label='CBH1')\n",
    "if np.all(merged_dict['aad_ceil']['cbh_2'] != np.nan):\n",
    "    ax3.scatter(merged_dict['basta']['time_dt'],merged_dict['aad_ceil']['cbh_2']*1.e-3,s=2,c='magenta',label='CBH2')\n",
    "if np.all(merged_dict['aad_ceil']['cbh_3'] != np.nan):\n",
    "    ax3.scatter(merged_dict['basta']['time_dt'],merged_dict['aad_ceil']['cbh_3']*1.e-3,s=2,c='cyan',label='CBH3')\n",
    "ax3.legend(fontsize=Fontsize,loc='upper left',ncol=1)\n",
    "\n",
    "\n",
    "\n",
    "for ax in axlist:\n",
    "    ax.set_ylabel('Height [km]',fontsize=Fontsize)\n",
    "    ax.set_xlabel('UTC Time [HH:MM]',fontsize=Fontsize)\n",
    "    ax.tick_params(labelsize=Fontsize)\n",
    "    ax.xaxis.set_major_formatter(dfmt)\n",
    "    ax.grid(True)\n",
    "    ax.set_ylim(0,1)\n",
    "    \n",
    "ax1.set_title('BASTA Reflectivity',fontsize=Fontsize*1.25,fontweight='bold')\n",
    "dumstr = '$log_{10}$($\\\\beta_{att}$)'\n",
    "ax2.set_title('Univ. of Canterbury CEIL Native {}'.format(dumstr),fontsize=Fontsize*1.25,fontweight='bold')\n",
    "ax3.set_title('Univ. of Canterbury CEIL Interpolated {}'.format(dumstr),fontsize=Fontsize*1.25,fontweight='bold')\n",
    "    \n",
    "datestr = datetime.datetime(basta_time_dt[0].year,basta_time_dt[0].month,basta_time_dt[0].day).strftime(\"%m/%d/%Y\")\n",
    "plt.suptitle(datestr,fontsize=Fontsize*2)\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
